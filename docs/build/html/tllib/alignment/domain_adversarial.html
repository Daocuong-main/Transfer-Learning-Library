


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Domain Adversarial Training &mdash; Transfer Learning Library 0.0.19 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" /> -->
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Hypothesis Adversarial Learning" href="hypothesis_adversarial.html" />
    <link rel="prev" title="Statistics Matching" href="statistics_matching.html" /> 

  
  <script src="../../_static/js/modernizr.min.js"></script>
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://shiftlab.github.io/pytorch/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://shiftlab.github.io/pytorch/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://shiftlab.github.io/pytorch/features">Features</a>
          </li>

          <li>
            <a href="https://shiftlab.github.io/pytorch/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://shiftlab.github.io/pytorch/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li>
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <a href="https://shiftlab.github.io/pytorch/resources">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>

  </div>
</div>


<body class="pytorch-body">

   
  <div>

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Transfer Learning API</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../modules.html">Modules</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Feature Alignment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../translation.html">Domain Translation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../self_training.html">Self Training Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reweight.html">Re-weighting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../normalization.html">Normalization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../regularization.html">Regularization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ranking.html">Ranking</a></li>
</ul>
<p class="caption"><span class="caption-text">Common API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../vision/index.html">Vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../utils/index.html">Utilities</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">

      <section data-toggle="wy-nav-shift" class="pytorch-content-wrap">
        <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
          <div class="pytorch-breadcrumbs-wrapper">
            















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="index.html">Feature Alignment</a> &gt;</li>
        
      <li>Domain Adversarial Training</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../../_sources/tllib/alignment/domain_adversarial.rst.txt" rel="nofollow"><img src="../../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
          </div>

          <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
            Shortcuts
          </div>
        </div>

        <div class="pytorch-content-left">
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" class="pytorch-article">
              
  <div class="section" id="domain-adversarial-training">
<h1>Domain Adversarial Training<a class="headerlink" href="#domain-adversarial-training" title="Permalink to this headline">¶</a></h1>
<div class="section" id="dann-domain-adversarial-neural-network">
<span id="dann"></span><h2>DANN: Domain Adversarial Neural Network<a class="headerlink" href="#dann-domain-adversarial-neural-network" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="tllib.alignment.dann.DomainAdversarialLoss">
<em class="property">class </em><code class="sig-prename descclassname">tllib.alignment.dann.</code><code class="sig-name descname">DomainAdversarialLoss</code><span class="sig-paren">(</span><em class="sig-param">domain_discriminator</em>, <em class="sig-param">reduction='mean'</em>, <em class="sig-param">grl=None</em>, <em class="sig-param">sigmoid=True</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/tllib/alignment/dann.html#DomainAdversarialLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#tllib.alignment.dann.DomainAdversarialLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>The Domain Adversarial Loss proposed in
<a class="reference external" href="https://arxiv.org/abs/1505.07818">Domain-Adversarial Training of Neural Networks (ICML 2015)</a></p>
<p>Domain adversarial loss measures the domain discrepancy through training a domain discriminator.
Given domain discriminator <span class="math notranslate nohighlight">\(D\)</span>, feature representation <span class="math notranslate nohighlight">\(f\)</span>, the definition of DANN loss is</p>
<div class="math notranslate nohighlight">
\[loss(\mathcal{D}_s, \mathcal{D}_t) = \mathbb{E}_{x_i^s \sim \mathcal{D}_s} \text{log}[D(f_i^s)]
    + \mathbb{E}_{x_j^t \sim \mathcal{D}_t} \text{log}[1-D(f_j^t)].\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>domain_discriminator</strong> (<a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v1.13)"><em>torch.nn.Module</em></a>) – A domain discriminator object, which predicts the domains of features. Its input shape is (N, F) and output shape is (N, 1)</p></li>
<li><p><strong>reduction</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>, </em><em>optional</em>) – Specifies the reduction to apply to the output:
<code class="docutils literal notranslate"><span class="pre">'none'</span></code> | <code class="docutils literal notranslate"><span class="pre">'mean'</span></code> | <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>. <code class="docutils literal notranslate"><span class="pre">'none'</span></code>: no reduction will be applied,
<code class="docutils literal notranslate"><span class="pre">'mean'</span></code>: the sum of the output will be divided by the number of
elements in the output, <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>: the output will be summed. Default: <code class="docutils literal notranslate"><span class="pre">'mean'</span></code></p></li>
<li><p><strong>grl</strong> (<a class="reference internal" href="../modules.html#tllib.modules.grl.WarmStartGradientReverseLayer" title="tllib.modules.grl.WarmStartGradientReverseLayer"><em>WarmStartGradientReverseLayer</em></a><em>, </em><em>optional</em>) – Default: None.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p>f_s (tensor): feature representations on source domain, <span class="math notranslate nohighlight">\(f^s\)</span></p></li>
<li><p>f_t (tensor): feature representations on target domain, <span class="math notranslate nohighlight">\(f^t\)</span></p></li>
<li><p>w_s (tensor, optional): a rescaling weight given to each instance from source domain.</p></li>
<li><p>w_t (tensor, optional): a rescaling weight given to each instance from target domain.</p></li>
</ul>
</dd>
<dt>Shape:</dt><dd><ul class="simple">
<li><p>f_s, f_t: <span class="math notranslate nohighlight">\((N, F)\)</span> where F means the dimension of input features.</p></li>
<li><p>Outputs: scalar by default. If <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> is <code class="docutils literal notranslate"><span class="pre">'none'</span></code>, then <span class="math notranslate nohighlight">\((N, )\)</span>.</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tllib.modules.domain_discriminator</span> <span class="kn">import</span> <span class="n">DomainDiscriminator</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">discriminator</span> <span class="o">=</span> <span class="n">DomainDiscriminator</span><span class="p">(</span><span class="n">in_feature</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">DomainAdversarialLoss</span><span class="p">(</span><span class="n">discriminator</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># features from source domain and target domain</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f_s</span><span class="p">,</span> <span class="n">f_t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">1024</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">1024</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># If you want to assign different weights to each instance, you should pass in w_s and w_t</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w_s</span><span class="p">,</span> <span class="n">w_t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">f_s</span><span class="p">,</span> <span class="n">f_t</span><span class="p">,</span> <span class="n">w_s</span><span class="p">,</span> <span class="n">w_t</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="cdan-conditional-domain-adversarial-network">
<span id="cdan"></span><h2>CDAN: Conditional Domain Adversarial Network<a class="headerlink" href="#cdan-conditional-domain-adversarial-network" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="tllib.alignment.cdan.ConditionalDomainAdversarialLoss">
<em class="property">class </em><code class="sig-prename descclassname">tllib.alignment.cdan.</code><code class="sig-name descname">ConditionalDomainAdversarialLoss</code><span class="sig-paren">(</span><em class="sig-param">domain_discriminator</em>, <em class="sig-param">entropy_conditioning=False</em>, <em class="sig-param">randomized=False</em>, <em class="sig-param">num_classes=-1</em>, <em class="sig-param">features_dim=-1</em>, <em class="sig-param">randomized_dim=1024</em>, <em class="sig-param">reduction='mean'</em>, <em class="sig-param">sigmoid=True</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/tllib/alignment/cdan.html#ConditionalDomainAdversarialLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#tllib.alignment.cdan.ConditionalDomainAdversarialLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>The Conditional Domain Adversarial Loss used in <a class="reference external" href="https://arxiv.org/abs/1705.10667">Conditional Adversarial Domain Adaptation (NIPS 2018)</a></p>
<p>Conditional Domain adversarial loss measures the domain discrepancy through training a domain discriminator in a
conditional manner. Given domain discriminator <span class="math notranslate nohighlight">\(D\)</span>, feature representation <span class="math notranslate nohighlight">\(f\)</span> and
classifier predictions <span class="math notranslate nohighlight">\(g\)</span>, the definition of CDAN loss is</p>
<div class="math notranslate nohighlight">
\[\begin{split}loss(\mathcal{D}_s, \mathcal{D}_t) &amp;= \mathbb{E}_{x_i^s \sim \mathcal{D}_s} \text{log}[D(T(f_i^s, g_i^s))] \\
&amp;+ \mathbb{E}_{x_j^t \sim \mathcal{D}_t} \text{log}[1-D(T(f_j^t, g_j^t))],\\\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(T\)</span> is a <a class="reference internal" href="#tllib.alignment.cdan.MultiLinearMap" title="tllib.alignment.cdan.MultiLinearMap"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiLinearMap</span></code></a>  or <a class="reference internal" href="#tllib.alignment.cdan.RandomizedMultiLinearMap" title="tllib.alignment.cdan.RandomizedMultiLinearMap"><code class="xref py py-class docutils literal notranslate"><span class="pre">RandomizedMultiLinearMap</span></code></a> which convert two tensors to a single tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>domain_discriminator</strong> (<a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v1.13)"><em>torch.nn.Module</em></a>) – A domain discriminator object, which predicts the domains of
features. Its input shape is (N, F) and output shape is (N, 1)</p></li>
<li><p><strong>entropy_conditioning</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.11)"><em>bool</em></a><em>, </em><em>optional</em>) – If True, use entropy-aware weight to reweight each training example.
Default: False</p></li>
<li><p><strong>randomized</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.11)"><em>bool</em></a><em>, </em><em>optional</em>) – If True, use <cite>randomized multi linear map</cite>. Else, use <cite>multi linear map</cite>.
Default: False</p></li>
<li><p><strong>num_classes</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a><em>, </em><em>optional</em>) – Number of classes. Default: -1</p></li>
<li><p><strong>features_dim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a><em>, </em><em>optional</em>) – Dimension of input features. Default: -1</p></li>
<li><p><strong>randomized_dim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a><em>, </em><em>optional</em>) – Dimension of features after randomized. Default: 1024</p></li>
<li><p><strong>reduction</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>, </em><em>optional</em>) – Specifies the reduction to apply to the output:
<code class="docutils literal notranslate"><span class="pre">'none'</span></code> | <code class="docutils literal notranslate"><span class="pre">'mean'</span></code> | <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>. <code class="docutils literal notranslate"><span class="pre">'none'</span></code>: no reduction will be applied,
<code class="docutils literal notranslate"><span class="pre">'mean'</span></code>: the sum of the output will be divided by the number of
elements in the output, <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>: the output will be summed. Default: <code class="docutils literal notranslate"><span class="pre">'mean'</span></code></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You need to provide <cite>num_classes</cite>, <cite>features_dim</cite> and <cite>randomized_dim</cite> <strong>only when</strong> <cite>randomized</cite>
is set True.</p>
</div>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p>g_s (tensor): unnormalized classifier predictions on source domain, <span class="math notranslate nohighlight">\(g^s\)</span></p></li>
<li><p>f_s (tensor): feature representations on source domain, <span class="math notranslate nohighlight">\(f^s\)</span></p></li>
<li><p>g_t (tensor): unnormalized classifier predictions on target domain, <span class="math notranslate nohighlight">\(g^t\)</span></p></li>
<li><p>f_t (tensor): feature representations on target domain, <span class="math notranslate nohighlight">\(f^t\)</span></p></li>
</ul>
</dd>
<dt>Shape:</dt><dd><ul class="simple">
<li><p>g_s, g_t: <span class="math notranslate nohighlight">\((minibatch, C)\)</span> where C means the number of classes.</p></li>
<li><p>f_s, f_t: <span class="math notranslate nohighlight">\((minibatch, F)\)</span> where F means the dimension of input features.</p></li>
<li><p>Output: scalar by default. If <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> is <code class="docutils literal notranslate"><span class="pre">'none'</span></code>, then <span class="math notranslate nohighlight">\((minibatch, )\)</span>.</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tllib.modules.domain_discriminator</span> <span class="kn">import</span> <span class="n">DomainDiscriminator</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tllib.alignment.cdan</span> <span class="kn">import</span> <span class="n">ConditionalDomainAdversarialLoss</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">num_classes</span> <span class="o">=</span> <span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">feature_dim</span> <span class="o">=</span> <span class="mi">1024</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">10</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">discriminator</span> <span class="o">=</span> <span class="n">DomainDiscriminator</span><span class="p">(</span><span class="n">in_feature</span><span class="o">=</span><span class="n">feature_dim</span> <span class="o">*</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">ConditionalDomainAdversarialLoss</span><span class="p">(</span><span class="n">discriminator</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># features from source domain and target domain</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f_s</span><span class="p">,</span> <span class="n">f_t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">feature_dim</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">feature_dim</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># logits output from source domain adn target domain</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">g_s</span><span class="p">,</span> <span class="n">g_t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">g_s</span><span class="p">,</span> <span class="n">f_s</span><span class="p">,</span> <span class="n">g_t</span><span class="p">,</span> <span class="n">f_t</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="class">
<dt id="tllib.alignment.cdan.RandomizedMultiLinearMap">
<em class="property">class </em><code class="sig-prename descclassname">tllib.alignment.cdan.</code><code class="sig-name descname">RandomizedMultiLinearMap</code><span class="sig-paren">(</span><em class="sig-param">features_dim</em>, <em class="sig-param">num_classes</em>, <em class="sig-param">output_dim=1024</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/tllib/alignment/cdan.html#RandomizedMultiLinearMap"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#tllib.alignment.cdan.RandomizedMultiLinearMap" title="Permalink to this definition">¶</a></dt>
<dd><p>Random multi linear map</p>
<p>Given two inputs <span class="math notranslate nohighlight">\(f\)</span> and <span class="math notranslate nohighlight">\(g\)</span>, the definition is</p>
<div class="math notranslate nohighlight">
\[T_{\odot}(f,g) = \dfrac{1}{\sqrt{d}} (R_f f) \odot (R_g g),\]</div>
<p>where <span class="math notranslate nohighlight">\(\odot\)</span> is element-wise product, <span class="math notranslate nohighlight">\(R_f\)</span> and <span class="math notranslate nohighlight">\(R_g\)</span> are random matrices
sampled only once and ﬁxed in training.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>features_dim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a>) – dimension of input <span class="math notranslate nohighlight">\(f\)</span></p></li>
<li><p><strong>num_classes</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a>) – dimension of input <span class="math notranslate nohighlight">\(g\)</span></p></li>
<li><p><strong>output_dim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a><em>, </em><em>optional</em>) – dimension of output tensor. Default: 1024</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>f: (minibatch, features_dim)</p></li>
<li><p>g: (minibatch, num_classes)</p></li>
<li><p>Outputs: (minibatch, output_dim)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="tllib.alignment.cdan.MultiLinearMap">
<em class="property">class </em><code class="sig-prename descclassname">tllib.alignment.cdan.</code><code class="sig-name descname">MultiLinearMap</code><a class="reference internal" href="../../_modules/tllib/alignment/cdan.html#MultiLinearMap"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#tllib.alignment.cdan.MultiLinearMap" title="Permalink to this definition">¶</a></dt>
<dd><p>Multi linear map</p>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>f: (minibatch, F)</p></li>
<li><p>g: (minibatch, C)</p></li>
<li><p>Outputs: (minibatch, F * C)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="adda-adversarial-discriminative-domain-adaptation">
<span id="adda"></span><h2>ADDA: Adversarial Discriminative Domain Adaptation<a class="headerlink" href="#adda-adversarial-discriminative-domain-adaptation" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="tllib.alignment.adda.DomainAdversarialLoss">
<em class="property">class </em><code class="sig-prename descclassname">tllib.alignment.adda.</code><code class="sig-name descname">DomainAdversarialLoss</code><a class="reference internal" href="../../_modules/tllib/alignment/adda.html#DomainAdversarialLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#tllib.alignment.adda.DomainAdversarialLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Domain adversarial loss from <a class="reference external" href="https://arxiv.org/pdf/1702.05464.pdf">Adversarial Discriminative Domain Adaptation (CVPR 2017)</a>.
Similar to the original <a class="reference external" href="https://arxiv.org/pdf/1406.2661.pdf">GAN</a> paper, ADDA argues that replacing
<span class="math notranslate nohighlight">\(\text{log}(1-p)\)</span> with <span class="math notranslate nohighlight">\(-\text{log}(p)\)</span> in the adversarial loss provides better gradient qualities. Detailed
optimization process can be found <a class="reference external" href="https://github.com/thuml/Transfer-Learning-Library/blob/master/examples/domain_adaptation/image_classification/adda.py">here</a>.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p>domain_pred (tensor): predictions of domain discriminator</p></li>
<li><p>domain_label (str, optional): whether the data comes from source or target.
Must be ‘source’ or ‘target’. Default: ‘source’</p></li>
</ul>
</dd>
<dt>Shape:</dt><dd><ul class="simple">
<li><p>domain_pred: <span class="math notranslate nohighlight">\((minibatch,)\)</span>.</p></li>
<li><p>Outputs: scalar.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<div class="admonition note">
<p class="admonition-title">Note</p>
<p>ADDAgrl is also implemented and benchmarked. You can find code
<a class="reference external" href="https://github.com/thuml/Transfer-Learning-Library/blob/master/examples/domain_adaptation/image_classification/addagrl.py">here</a>.</p>
</div>
</div>
<div class="section" id="bsp-batch-spectral-penalization">
<span id="bsp"></span><h2>BSP: Batch Spectral Penalization<a class="headerlink" href="#bsp-batch-spectral-penalization" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="tllib.alignment.bsp.BatchSpectralPenalizationLoss">
<em class="property">class </em><code class="sig-prename descclassname">tllib.alignment.bsp.</code><code class="sig-name descname">BatchSpectralPenalizationLoss</code><a class="reference internal" href="../../_modules/tllib/alignment/bsp.html#BatchSpectralPenalizationLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#tllib.alignment.bsp.BatchSpectralPenalizationLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Batch spectral penalization loss from <a class="reference external" href="http://ise.thss.tsinghua.edu.cn/~mlong/doc/batch-spectral-penalization-icml19.pdf">Transferability vs. Discriminability: Batch
Spectral Penalization for Adversarial Domain Adaptation (ICML 2019)</a>.</p>
<p>Given source features <span class="math notranslate nohighlight">\(f_s\)</span> and target features <span class="math notranslate nohighlight">\(f_t\)</span> in current mini batch, singular value
decomposition is first performed</p>
<div class="math notranslate nohighlight">
\[f_s = U_s\Sigma_sV_s^T\]</div>
<div class="math notranslate nohighlight">
\[f_t = U_t\Sigma_tV_t^T\]</div>
<p>Then batch spectral penalization loss is calculated as</p>
<div class="math notranslate nohighlight">
\[loss=\sum_{i=1}^k(\sigma_{s,i}^2+\sigma_{t,i}^2)\]</div>
<p>where <span class="math notranslate nohighlight">\(\sigma_{s,i},\sigma_{t,i}\)</span> refer to the <span class="math notranslate nohighlight">\(i-th\)</span> largest singular value of source features
and target features respectively. We empirically set <span class="math notranslate nohighlight">\(k=1\)</span>.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p>f_s (tensor): feature representations on source domain, <span class="math notranslate nohighlight">\(f^s\)</span></p></li>
<li><p>f_t (tensor): feature representations on target domain, <span class="math notranslate nohighlight">\(f^t\)</span></p></li>
</ul>
</dd>
<dt>Shape:</dt><dd><ul class="simple">
<li><p>f_s, f_t: <span class="math notranslate nohighlight">\((N, F)\)</span> where F means the dimension of input features.</p></li>
<li><p>Outputs: scalar.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="osbp-open-set-domain-adaptation-by-backpropagation">
<span id="osbp"></span><h2>OSBP: Open Set Domain Adaptation by Backpropagation<a class="headerlink" href="#osbp-open-set-domain-adaptation-by-backpropagation" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="tllib.alignment.osbp.UnknownClassBinaryCrossEntropy">
<em class="property">class </em><code class="sig-prename descclassname">tllib.alignment.osbp.</code><code class="sig-name descname">UnknownClassBinaryCrossEntropy</code><span class="sig-paren">(</span><em class="sig-param">t=0.5</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/tllib/alignment/osbp.html#UnknownClassBinaryCrossEntropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#tllib.alignment.osbp.UnknownClassBinaryCrossEntropy" title="Permalink to this definition">¶</a></dt>
<dd><p>Binary cross entropy loss to make a boundary for unknown samples, proposed by
<a class="reference external" href="https://arxiv.org/abs/1804.10427">Open Set Domain Adaptation by Backpropagation (ECCV 2018)</a>.</p>
<p>Given a sample on target domain <span class="math notranslate nohighlight">\(x_t\)</span> and its classifcation outputs <span class="math notranslate nohighlight">\(y\)</span>, the binary cross entropy
loss is defined as</p>
<div class="math notranslate nohighlight">
\[L_{\text{adv}}(x_t) = -t \text{log}(p(y=C+1|x_t)) - (1-t)\text{log}(1-p(y=C+1|x_t))\]</div>
<p>where t is a hyper-parameter and C is the number of known classes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>t</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.11)"><em>float</em></a>) – Predefined hyper-parameter. Default: 0.5</p>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p>y (tensor): classification outputs (before softmax).</p></li>
</ul>
</dd>
<dt>Shape:</dt><dd><ul class="simple">
<li><p>y: <span class="math notranslate nohighlight">\((minibatch, C+1)\)</span>  where C is the number of known classes.</p></li>
<li><p>Outputs: scalar</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="advent-adversarial-entropy-minimization-for-semantic-segmentation">
<span id="advent"></span><h2>ADVENT: Adversarial Entropy Minimization for Semantic Segmentation<a class="headerlink" href="#advent-adversarial-entropy-minimization-for-semantic-segmentation" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="tllib.alignment.advent.Discriminator">
<em class="property">class </em><code class="sig-prename descclassname">tllib.alignment.advent.</code><code class="sig-name descname">Discriminator</code><span class="sig-paren">(</span><em class="sig-param">num_classes</em>, <em class="sig-param">ndf=64</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/tllib/alignment/advent.html#Discriminator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#tllib.alignment.advent.Discriminator" title="Permalink to this definition">¶</a></dt>
<dd><p>Domain discriminator model from
<a class="reference external" href="https://arxiv.org/abs/1811.12833">ADVENT: Adversarial Entropy Minimization for Domain Adaptation in Semantic Segmentation (CVPR 2019)</a></p>
<p>Distinguish pixel-by-pixel whether the input predictions come from the source domain or the target domain.
The source domain label is 1 and the target domain label is 0.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_classes</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a>) – num of classes in the predictions</p></li>
<li><p><strong>ndf</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a>) – dimension of the hidden features</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Inputs: <span class="math notranslate nohighlight">\((minibatch, C, H, W)\)</span> where <span class="math notranslate nohighlight">\(C\)</span> is the number of classes</p></li>
<li><p>Outputs: <span class="math notranslate nohighlight">\((minibatch, 1, H, W)\)</span></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="tllib.alignment.advent.DomainAdversarialEntropyLoss">
<em class="property">class </em><code class="sig-prename descclassname">tllib.alignment.advent.</code><code class="sig-name descname">DomainAdversarialEntropyLoss</code><span class="sig-paren">(</span><em class="sig-param">discriminator</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/tllib/alignment/advent.html#DomainAdversarialEntropyLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#tllib.alignment.advent.DomainAdversarialEntropyLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>The <a class="reference external" href="https://arxiv.org/abs/1811.12833">Domain Adversarial Entropy Loss</a></p>
<p>Minimizing entropy with adversarial learning through training a domain discriminator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>domain_discriminator</strong> (<a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v1.13)"><em>torch.nn.Module</em></a>) – A domain discriminator object, which predicts
the domains of predictions. Its input shape is <span class="math notranslate nohighlight">\((minibatch, C, H, W)\)</span> and output shape is <span class="math notranslate nohighlight">\((minibatch, 1, H, W)\)</span></p>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p>logits (tensor): logits output of segmentation model</p></li>
<li><p>domain_label (str, optional): whether the data comes from source or target.
Choices: [‘source’, ‘target’]. Default: ‘source’</p></li>
</ul>
</dd>
<dt>Shape:</dt><dd><ul class="simple">
<li><p>logits: <span class="math notranslate nohighlight">\((minibatch, C, H, W)\)</span> where <span class="math notranslate nohighlight">\(C\)</span> means the number of classes</p></li>
<li><p>Outputs: scalar.</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">B</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">19</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">512</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">discriminator</span> <span class="o">=</span> <span class="n">Discriminator</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="n">C</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dann</span> <span class="o">=</span> <span class="n">DomainAdversarialEntropyLoss</span><span class="p">(</span><span class="n">discriminator</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># logits output on source domain and target domain</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_s</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">dann</span><span class="p">(</span><span class="n">y_s</span><span class="p">,</span> <span class="s2">&quot;source&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="n">dann</span><span class="p">(</span><span class="n">y_t</span><span class="p">,</span> <span class="s2">&quot;target&quot;</span><span class="p">))</span>
</pre></div>
</div>
<dl class="method">
<dt id="tllib.alignment.advent.DomainAdversarialEntropyLoss.eval">
<code class="sig-name descname">eval</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/tllib/alignment/advent.html#DomainAdversarialEntropyLoss.eval"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#tllib.alignment.advent.DomainAdversarialEntropyLoss.eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the module in evaluation mode. In the training mode,
all the parameters in discriminator will be set requires_grad=False.</p>
<p>This is equivalent with <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.train" title="(in PyTorch v1.13)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">self.train(False)</span></code></a>.</p>
</dd></dl>

<dl class="method">
<dt id="tllib.alignment.advent.DomainAdversarialEntropyLoss.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">logits</em>, <em class="sig-param">domain_label='source'</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/tllib/alignment/advent.html#DomainAdversarialEntropyLoss.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#tllib.alignment.advent.DomainAdversarialEntropyLoss.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="tllib.alignment.advent.DomainAdversarialEntropyLoss.train">
<code class="sig-name descname">train</code><span class="sig-paren">(</span><em class="sig-param">mode=True</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/tllib/alignment/advent.html#DomainAdversarialEntropyLoss.train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#tllib.alignment.advent.DomainAdversarialEntropyLoss.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the discriminator in training mode. In the training mode,
all the parameters in discriminator will be set requires_grad=True.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>mode</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.11)"><em>bool</em></a>) – whether to set training mode (<code class="docutils literal notranslate"><span class="pre">True</span></code>) or evaluation mode (<code class="docutils literal notranslate"><span class="pre">False</span></code>). Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="d-adapt-decoupled-adaptation-for-cross-domain-object-detection">
<span id="dadapt"></span><h2>D-adapt: Decoupled Adaptation for Cross-Domain Object Detection<a class="headerlink" href="#d-adapt-decoupled-adaptation-for-cross-domain-object-detection" title="Permalink to this headline">¶</a></h2>
<p><a class="reference external" href="https://openreview.net/pdf?id=VNqaB1g9393">Origin Paper</a>.</p>
</div>
</div>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="hypothesis_adversarial.html" class="btn btn-neutral float-right" title="Hypothesis Adversarial Learning" accesskey="n" rel="next">Next <img src="../../_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="statistics_matching.html" class="btn btn-neutral" title="Statistics Matching" accesskey="p" rel="prev"><img src="../../_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright THUML Group.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">Domain Adversarial Training</a><ul>
<li><a class="reference internal" href="#dann-domain-adversarial-neural-network">DANN: Domain Adversarial Neural Network</a></li>
<li><a class="reference internal" href="#cdan-conditional-domain-adversarial-network">CDAN: Conditional Domain Adversarial Network</a></li>
<li><a class="reference internal" href="#adda-adversarial-discriminative-domain-adaptation">ADDA: Adversarial Discriminative Domain Adaptation</a></li>
<li><a class="reference internal" href="#bsp-batch-spectral-penalization">BSP: Batch Spectral Penalization</a></li>
<li><a class="reference internal" href="#osbp-open-set-domain-adaptation-by-backpropagation">OSBP: Open Set Domain Adaptation by Backpropagation</a></li>
<li><a class="reference internal" href="#advent-adversarial-entropy-minimization-for-semantic-segmentation">ADVENT: Adversarial Entropy Minimization for Semantic Segmentation</a></li>
<li><a class="reference internal" href="#d-adapt-decoupled-adaptation-for-cross-domain-object-detection">D-adapt: Decoupled Adaptation for Cross-Domain Object Detection</a></li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>
  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../',
            VERSION:'0.0.19',
            LANGUAGE:'en',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../_static/doctools.js"></script>
      <script type="text/javascript" src="../../_static/language_data.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  <script type="text/javascript" src="../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../_static/js/vendor/bootstrap.min.js"></script>
  <script type="text/javascript" src="../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(false);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Lorem ipsum dolor sit amet, consectetur</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Lorem ipsum dolor sit amet, consectetur</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Lorem ipsum dolor sit amet, consectetur</p>
          <a class="with-right-arrow" href="https://shiftlab.github.io/pytorch/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://shiftlab.github.io/pytorch/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://shiftlab.github.io/pytorch/">PyTorch</a></li>
            <li><a href="https://shiftlab.github.io/pytorch/get-started">Get Started</a></li>
            <li><a href="https://shiftlab.github.io/pytorch/features">Features</a></li>
            <li><a href="https://shiftlab.github.io/pytorch/ecosystem">Ecosystem</a></li>
            <li><a href="https://shiftlab.github.io/pytorch/blog/">Blog</a></li>
            <li><a href="https://shiftlab.github.io/pytorch/resources">Resources</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://shiftlab.github.io/pytorch/support">Support</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.slack.com" target="_blank">Slack</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md" target="_blank">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Follow Us</li>
            <li>
              <div id="mc_embed_signup">
                <form
                  action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&id=91d0dccd39"
                  method="post"
                  id="mc-embedded-subscribe-form"
                  name="mc-embedded-subscribe-form"
                  class="email-subscribe-form validate"
                  target="_blank"
                  novalidate>
                  <div id="mc_embed_signup_scroll" class="email-subscribe-form-fields-wrapper">
                    <div class="mc-field-group">
                      <label for="mce-EMAIL" style="display:none;">Email Address</label>
                      <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="Email Address">
                    </div>

                    <div id="mce-responses" class="clear">
                      <div class="response" id="mce-error-response" style="display:none"></div>
                      <div class="response" id="mce-success-response" style="display:none"></div>
                    </div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->

                    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" value=""></div>

                    <div class="clear">
                      <input type="submit" value="" name="subscribe" id="mc-embedded-subscribe" class="button email-subscribe-button">
                    </div>
                  </div>
                </form>
              </div>

            </li>
          </ul>

          <div class="footer-social-icons">
            <a href="https://www.facebook.com/pytorch" target="_blank" class="facebook"></a>
            <a href="https://twitter.com/pytorch" target="_blank" class="twitter"></a>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://shiftlab.github.io/pytorch/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="#">Get Started</a>
          </li>

          <li>
            <a href="#">Features</a>
          </li>

          <li>
            <a href="#">Ecosystem</a>
          </li>

          <li>
            <a href="https://shiftlab.github.io/pytorch/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li>
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <a href="https://shiftlab.github.io/pytorch/resources">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    mobileMenu.bind();
    mobileTOC.bind();
    pytorchAnchors.bind();

    $(window).on("load", function() {
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
    })

    // Add class to links that have code blocks, since we cannot create links in code blocks
    $("article.pytorch-article a span.pre").each(function(e) {
      $(this).closest("a").addClass("has-code");
    });
  </script>
</body>
</html>