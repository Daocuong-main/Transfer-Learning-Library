


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>tllib.vision.models.reid.loss &mdash; Transfer Learning Library 0.0.19 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../../../../_static/pygments.css" type="text/css" /> -->
    <link rel="index" title="Index" href="../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../search.html" /> 

  
  <script src="../../../../../_static/js/modernizr.min.js"></script>
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://shiftlab.github.io/pytorch/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://shiftlab.github.io/pytorch/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://shiftlab.github.io/pytorch/features">Features</a>
          </li>

          <li>
            <a href="https://shiftlab.github.io/pytorch/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://shiftlab.github.io/pytorch/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li>
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <a href="https://shiftlab.github.io/pytorch/resources">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>

  </div>
</div>


<body class="pytorch-body">

   
  <div>

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Transfer Learning API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tllib/modules.html">Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tllib/alignment/index.html">Feature Alignment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tllib/translation.html">Domain Translation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tllib/self_training.html">Self Training Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tllib/reweight.html">Re-weighting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tllib/normalization.html">Normalization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tllib/regularization.html">Regularization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tllib/ranking.html">Ranking</a></li>
</ul>
<p class="caption"><span class="caption-text">Common API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tllib/vision/index.html">Vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tllib/utils/index.html">Utilities</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">

      <section data-toggle="wy-nav-shift" class="pytorch-content-wrap">
        <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
          <div class="pytorch-breadcrumbs-wrapper">
            















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../../../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../../../../index.html">Module code</a> &gt;</li>
        
      <li>tllib.vision.models.reid.loss</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
          </div>

          <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
            Shortcuts
          </div>
        </div>

        <div class="pytorch-content-left">
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" class="pytorch-article">
              
  <h1>Source code for tllib.vision.models.reid.loss</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Modified from https://github.com/yxgeee/MMT</span>
<span class="sd">@author: Baixu Chen</span>
<span class="sd">@contact: cbx_99_hasta@outlook.com</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>


<span class="k">def</span> <span class="nf">pairwise_euclidean_distance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute pairwise euclidean distance between two sets of features&quot;&quot;&quot;</span>
    <span class="n">m</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">dist_mat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span> <span class="o">+</span> \
               <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span><span class="o">.</span><span class="n">t</span><span class="p">()</span> \
               <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">t</span><span class="p">())</span>
    <span class="c1"># for numerical stability</span>
    <span class="n">dist_mat</span> <span class="o">=</span> <span class="n">dist_mat</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">)</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">dist_mat</span>


<span class="k">def</span> <span class="nf">hard_examples_mining</span><span class="p">(</span><span class="n">dist_mat</span><span class="p">,</span> <span class="n">identity_mat</span><span class="p">,</span> <span class="n">return_idxes</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Select hard positives and hard negatives according to `In defense of the Triplet Loss for Person</span>
<span class="sd">    Re-Identification (ICCV 2017) &lt;https://arxiv.org/pdf/1703.07737v2.pdf&gt;`_</span>

<span class="sd">    Args:</span>
<span class="sd">        dist_mat (tensor): pairwise distance matrix between two sets of features</span>
<span class="sd">        identity_mat (tensor): a matrix of shape :math:`(N, M)`. If two images :math:`P[i]` of set :math:`P` and</span>
<span class="sd">            :math:`Q[j]` of set :math:`Q` come from the same person, then :math:`identity\_mat[i, j] = 1`,</span>
<span class="sd">            otherwise :math:`identity\_mat[i, j] = 0`</span>
<span class="sd">        return_idxes (bool, optional): if True, also return indexes of hard examples. Default: False</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># the implementation here is a little tricky, dist_mat contains pairwise distance between probe image and other</span>
    <span class="c1"># images in current mini-batch. As we want to select positive examples of the same person, we add a constant</span>
    <span class="c1"># negative offset on other images before sorting. As a result, images of the **same** person will rank first.</span>
    <span class="n">sorted_dist_mat</span><span class="p">,</span> <span class="n">sorted_idxes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">dist_mat</span> <span class="o">+</span> <span class="p">(</span><span class="o">-</span><span class="mf">1e7</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">identity_mat</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                               <span class="n">descending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">dist_ap</span> <span class="o">=</span> <span class="n">sorted_dist_mat</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">hard_positive_idxes</span> <span class="o">=</span> <span class="n">sorted_idxes</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>

    <span class="c1"># the implementation here is similar to above code, we add a constant positive offset on images of same person</span>
    <span class="c1"># before sorting. Besides, we sort in ascending order. As a result, images of **different** persons will rank first.</span>
    <span class="n">sorted_dist_mat</span><span class="p">,</span> <span class="n">sorted_idxes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">dist_mat</span> <span class="o">+</span> <span class="mf">1e7</span> <span class="o">*</span> <span class="n">identity_mat</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                               <span class="n">descending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">dist_an</span> <span class="o">=</span> <span class="n">sorted_dist_mat</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">hard_negative_idxes</span> <span class="o">=</span> <span class="n">sorted_idxes</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">return_idxes</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">dist_ap</span><span class="p">,</span> <span class="n">dist_an</span><span class="p">,</span> <span class="n">hard_positive_idxes</span><span class="p">,</span> <span class="n">hard_negative_idxes</span>
    <span class="k">return</span> <span class="n">dist_ap</span><span class="p">,</span> <span class="n">dist_an</span>


<span class="k">class</span> <span class="nc">CrossEntropyLossWithLabelSmooth</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Cross entropy loss with label smooth from `Rethinking the Inception Architecture for Computer Vision</span>
<span class="sd">    (CVPR 2016) &lt;https://arxiv.org/pdf/1512.00567.pdf&gt;`_.</span>

<span class="sd">    Given one-hot labels :math:`labels \in R^C`, where :math:`C` is the number of classes,</span>
<span class="sd">    smoothed labels are calculated as</span>

<span class="sd">    .. math::</span>
<span class="sd">        smoothed\_labels = (1 - \epsilon) \times labels + \epsilon \times \frac{1}{C}</span>

<span class="sd">    We use smoothed labels when calculating cross entropy loss and this can be helpful for preventing over-fitting.</span>

<span class="sd">    Args:</span>
<span class="sd">        num_classes (int): number of classes.</span>
<span class="sd">        epsilon (float): a float number that controls the smoothness.</span>

<span class="sd">    Inputs:</span>
<span class="sd">        - y (tensor): unnormalized classifier predictions, :math:`y`</span>
<span class="sd">        - labels (tensor): ground truth labels, :math:`labels`</span>

<span class="sd">    Shape:</span>
<span class="sd">        - y: :math:`(minibatch, C)`, where :math:`C` is the number of classes</span>
<span class="sd">        - labels: :math:`(minibatch, )`</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CrossEntropyLossWithLabelSmooth</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="n">num_classes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_softmax</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LogSoftmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
        <span class="n">log_prob</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">log_prob</span><span class="p">)</span><span class="o">.</span><span class="n">scatter_</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">labels</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">)</span> <span class="o">*</span> <span class="n">labels</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span> <span class="n">labels</span> <span class="o">*</span> <span class="n">log_prob</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">loss</span>


<div class="viewcode-block" id="TripletLoss"><a class="viewcode-back" href="../../../../../tllib/vision/models.html#tllib.vision.models.reid.loss.TripletLoss">[docs]</a><span class="k">class</span> <span class="nc">TripletLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Triplet loss augmented with batch hard from `In defense of the Triplet Loss for Person Re-Identification</span>
<span class="sd">    (ICCV 2017) &lt;https://arxiv.org/pdf/1703.07737v2.pdf&gt;`_.</span>

<span class="sd">    Args:</span>
<span class="sd">        margin (float): margin of triplet loss</span>
<span class="sd">        normalize_feature (bool, optional): if True, normalize features into unit norm first before computing loss.</span>
<span class="sd">            Default: False.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">margin</span><span class="p">,</span> <span class="n">normalize_feature</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TripletLoss</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">margin</span> <span class="o">=</span> <span class="n">margin</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">normalize_feature</span> <span class="o">=</span> <span class="n">normalize_feature</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">margin_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MarginRankingLoss</span><span class="p">(</span><span class="n">margin</span><span class="o">=</span><span class="n">margin</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize_feature</span><span class="p">:</span>
            <span class="c1"># equivalent to cosine similarity</span>
            <span class="n">f</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
        <span class="n">dist_mat</span> <span class="o">=</span> <span class="n">pairwise_euclidean_distance</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>

        <span class="n">n</span> <span class="o">=</span> <span class="n">dist_mat</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">identity_mat</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span><span class="o">.</span><span class="n">t</span><span class="p">())</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

        <span class="n">dist_ap</span><span class="p">,</span> <span class="n">dist_an</span> <span class="o">=</span> <span class="n">hard_examples_mining</span><span class="p">(</span><span class="n">dist_mat</span><span class="p">,</span> <span class="n">identity_mat</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">dist_ap</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">margin_loss</span><span class="p">(</span><span class="n">dist_an</span><span class="p">,</span> <span class="n">dist_ap</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span></div>


<span class="k">class</span> <span class="nc">TripletLossXBM</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Triplet loss augmented with batch hard from `In defense of the Triplet Loss for Person Re-Identification</span>
<span class="sd">    (ICCV 2017) &lt;https://arxiv.org/pdf/1703.07737v2.pdf&gt;`_. The only difference from triplet loss lies in that</span>
<span class="sd">    both features from current mini batch and external storage (XBM) are involved.</span>

<span class="sd">    Args:</span>
<span class="sd">        margin (float, optional): margin of triplet loss. Default: 0.3</span>
<span class="sd">        normalize_feature (bool, optional): if True, normalize features into unit norm first before computing loss.</span>
<span class="sd">            Default: False</span>

<span class="sd">    Inputs:</span>
<span class="sd">        - f (tensor): features of current mini batch, :math:`f`</span>
<span class="sd">        - labels (tensor): identity labels for current mini batch, :math:`labels`</span>
<span class="sd">        - xbm_f (tensor): features collected from XBM, :math:`xbm\_f`</span>
<span class="sd">        - xbm_labels (tensor): corresponding identity labels of xbm_f, :math:`xbm\_labels`</span>

<span class="sd">    Shape:</span>
<span class="sd">        - f: :math:`(minibatch, F)`, where :math:`F` is the feature dimension</span>
<span class="sd">        - labels: :math:`(minibatch, )`</span>
<span class="sd">        - xbm_f: :math:`(minibatch, F)`</span>
<span class="sd">        - xbm_labels: :math:`(minibatch, )`</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">margin</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">normalize_feature</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TripletLossXBM</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">margin</span> <span class="o">=</span> <span class="n">margin</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">normalize_feature</span> <span class="o">=</span> <span class="n">normalize_feature</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ranking_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MarginRankingLoss</span><span class="p">(</span><span class="n">margin</span><span class="o">=</span><span class="n">margin</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">xbm_f</span><span class="p">,</span> <span class="n">xbm_labels</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize_feature</span><span class="p">:</span>
            <span class="c1"># equivalent to cosine similarity</span>
            <span class="n">f</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
            <span class="n">xbm_f</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">xbm_f</span><span class="p">)</span>

        <span class="n">dist_mat</span> <span class="o">=</span> <span class="n">pairwise_euclidean_distance</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">xbm_f</span><span class="p">)</span>

        <span class="c1"># hard examples mining</span>
        <span class="n">n</span><span class="p">,</span> <span class="n">m</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">xbm_f</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">identity_mat</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span><span class="o">.</span><span class="n">t</span><span class="p">()</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">xbm_labels</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">))</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="n">dist_ap</span><span class="p">,</span> <span class="n">dist_an</span> <span class="o">=</span> <span class="n">hard_examples_mining</span><span class="p">(</span><span class="n">dist_mat</span><span class="p">,</span> <span class="n">identity_mat</span><span class="p">)</span>

        <span class="c1"># Compute ranking hinge loss</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">dist_an</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ranking_loss</span><span class="p">(</span><span class="n">dist_an</span><span class="p">,</span> <span class="n">dist_ap</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">loss</span>


<div class="viewcode-block" id="SoftTripletLoss"><a class="viewcode-back" href="../../../../../tllib/self_training.html#tllib.vision.models.reid.loss.SoftTripletLoss">[docs]</a><span class="k">class</span> <span class="nc">SoftTripletLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Soft triplet loss from `Mutual Mean-Teaching: Pseudo Label Refinery for Unsupervised</span>
<span class="sd">    Domain Adaptation on Person Re-identification (ICLR 2020) &lt;https://arxiv.org/pdf/2001.01526.pdf&gt;`_.</span>
<span class="sd">    Consider a triplet :math:`x,x_p,x_n` (anchor, positive, negative), corresponding features are :math:`f,f_p,f_n`.</span>
<span class="sd">    We optimize for a smaller distance between :math:`f` and :math:`f_p` and a larger distance</span>
<span class="sd">    between :math:`f` and :math:`f_n`. Inner product is adopted as their similarity measure, soft triplet loss is thus</span>
<span class="sd">    defined as</span>

<span class="sd">    .. math::</span>
<span class="sd">        loss = \mathcal{L}_{\text{bce}}(\frac{\text{exp}(f^Tf_p)}{\text{exp}(f^Tf_p)+\text{exp}(f^Tf_n)}, 1)</span>

<span class="sd">    where :math:`\mathcal{L}_{\text{bce}}` means binary cross entropy loss. We denote the first term in above loss function</span>
<span class="sd">    as :math:`T`. When features from another teacher network can be obtained, we can calculate :math:`T_{teacher}` as</span>
<span class="sd">    labels, resulting in the following soft version</span>

<span class="sd">    .. math::</span>
<span class="sd">        loss = \mathcal{L}_{\text{bce}}(T, T_{teacher})</span>

<span class="sd">    Args:</span>
<span class="sd">        margin (float, optional): margin of triplet loss. If None, soft labels from another network will be adopted when</span>
<span class="sd">            computing loss. Default: None.</span>
<span class="sd">        normalize_feature (bool, optional): if True, normalize features into unit norm first before computing loss.</span>
<span class="sd">            Default: False.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">margin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">normalize_feature</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SoftTripletLoss</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">margin</span> <span class="o">=</span> <span class="n">margin</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">normalize_feature</span> <span class="o">=</span> <span class="n">normalize_feature</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features_1</span><span class="p">,</span> <span class="n">features_2</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize_feature</span><span class="p">:</span>
            <span class="c1"># equal to cosine similarity</span>
            <span class="n">features_1</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">features_1</span><span class="p">)</span>
            <span class="n">features_2</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">features_2</span><span class="p">)</span>

        <span class="n">dist_mat</span> <span class="o">=</span> <span class="n">pairwise_euclidean_distance</span><span class="p">(</span><span class="n">features_1</span><span class="p">,</span> <span class="n">features_1</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">dist_mat</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">==</span> <span class="n">dist_mat</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">n</span> <span class="o">=</span> <span class="n">dist_mat</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">identity_mat</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span><span class="o">.</span><span class="n">t</span><span class="p">())</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

        <span class="n">dist_ap</span><span class="p">,</span> <span class="n">dist_an</span><span class="p">,</span> <span class="n">ap_idxes</span><span class="p">,</span> <span class="n">an_idxes</span> <span class="o">=</span> <span class="n">hard_examples_mining</span><span class="p">(</span><span class="n">dist_mat</span><span class="p">,</span> <span class="n">identity_mat</span><span class="p">,</span> <span class="n">return_idxes</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">dist_an</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">==</span> <span class="n">dist_ap</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">triple_dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">dist_ap</span><span class="p">,</span> <span class="n">dist_an</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">triple_dist</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">triple_dist</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">margin</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">margin</span> <span class="o">*</span> <span class="n">triple_dist</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">margin</span><span class="p">)</span> <span class="o">*</span> <span class="n">triple_dist</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">loss</span>

        <span class="n">dist_mat_ref</span> <span class="o">=</span> <span class="n">pairwise_euclidean_distance</span><span class="p">(</span><span class="n">features_2</span><span class="p">,</span> <span class="n">features_2</span><span class="p">)</span>
        <span class="n">dist_ap_ref</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">dist_mat_ref</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">ap_idxes</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">))[:,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="n">dist_an_ref</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">dist_mat_ref</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">an_idxes</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">))[:,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="n">triple_dist_ref</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">dist_ap_ref</span><span class="p">,</span> <span class="n">dist_an_ref</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">triple_dist_ref</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">triple_dist_ref</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span> <span class="n">triple_dist_ref</span> <span class="o">*</span> <span class="n">triple_dist</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">loss</span></div>


<div class="viewcode-block" id="CrossEntropyLoss"><a class="viewcode-back" href="../../../../../tllib/self_training.html#tllib.vision.models.reid.loss.CrossEntropyLoss">[docs]</a><span class="k">class</span> <span class="nc">CrossEntropyLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;We use :math:`C` to denote the number of classes, :math:`N` to denote mini-batch</span>
<span class="sd">    size, this criterion expects unnormalized predictions :math:`y\_{logits}` of shape :math:`(N, C)` and</span>
<span class="sd">    :math:`target\_{logits}` of the same shape :math:`(N, C)`. Then we first normalize them into</span>
<span class="sd">    probability distributions among classes</span>

<span class="sd">    .. math::</span>
<span class="sd">        y = \text{softmax}(y\_{logits})</span>
<span class="sd">    .. math::</span>
<span class="sd">        target = \text{softmax}(target\_{logits})</span>

<span class="sd">    Final objective is calculated as</span>

<span class="sd">    .. math::</span>
<span class="sd">        \text{loss} = \frac{1}{N} \sum_{i=1}^{N} \sum_{j=1}^C -target_i^j \times \text{log} (y_i^j)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CrossEntropyLoss</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_softmax</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LogSoftmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
        <span class="n">log_prob</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span> <span class="o">*</span> <span class="n">log_prob</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">loss</span></div>
</pre></div>

             </article>
             
            </div>
            <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright THUML Group.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>
  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../../../../',
            VERSION:'0.0.19',
            LANGUAGE:'en',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../../../../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../../../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../../../../_static/doctools.js"></script>
      <script type="text/javascript" src="../../../../../_static/language_data.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  <script type="text/javascript" src="../../../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../../../_static/js/vendor/bootstrap.min.js"></script>
  <script type="text/javascript" src="../../../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(false);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Lorem ipsum dolor sit amet, consectetur</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Lorem ipsum dolor sit amet, consectetur</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Lorem ipsum dolor sit amet, consectetur</p>
          <a class="with-right-arrow" href="https://shiftlab.github.io/pytorch/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://shiftlab.github.io/pytorch/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://shiftlab.github.io/pytorch/">PyTorch</a></li>
            <li><a href="https://shiftlab.github.io/pytorch/get-started">Get Started</a></li>
            <li><a href="https://shiftlab.github.io/pytorch/features">Features</a></li>
            <li><a href="https://shiftlab.github.io/pytorch/ecosystem">Ecosystem</a></li>
            <li><a href="https://shiftlab.github.io/pytorch/blog/">Blog</a></li>
            <li><a href="https://shiftlab.github.io/pytorch/resources">Resources</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://shiftlab.github.io/pytorch/support">Support</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.slack.com" target="_blank">Slack</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md" target="_blank">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Follow Us</li>
            <li>
              <div id="mc_embed_signup">
                <form
                  action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&id=91d0dccd39"
                  method="post"
                  id="mc-embedded-subscribe-form"
                  name="mc-embedded-subscribe-form"
                  class="email-subscribe-form validate"
                  target="_blank"
                  novalidate>
                  <div id="mc_embed_signup_scroll" class="email-subscribe-form-fields-wrapper">
                    <div class="mc-field-group">
                      <label for="mce-EMAIL" style="display:none;">Email Address</label>
                      <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="Email Address">
                    </div>

                    <div id="mce-responses" class="clear">
                      <div class="response" id="mce-error-response" style="display:none"></div>
                      <div class="response" id="mce-success-response" style="display:none"></div>
                    </div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->

                    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" value=""></div>

                    <div class="clear">
                      <input type="submit" value="" name="subscribe" id="mc-embedded-subscribe" class="button email-subscribe-button">
                    </div>
                  </div>
                </form>
              </div>

            </li>
          </ul>

          <div class="footer-social-icons">
            <a href="https://www.facebook.com/pytorch" target="_blank" class="facebook"></a>
            <a href="https://twitter.com/pytorch" target="_blank" class="twitter"></a>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://shiftlab.github.io/pytorch/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="#">Get Started</a>
          </li>

          <li>
            <a href="#">Features</a>
          </li>

          <li>
            <a href="#">Ecosystem</a>
          </li>

          <li>
            <a href="https://shiftlab.github.io/pytorch/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li>
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <a href="https://shiftlab.github.io/pytorch/resources">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    mobileMenu.bind();
    mobileTOC.bind();
    pytorchAnchors.bind();

    $(window).on("load", function() {
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
    })

    // Add class to links that have code blocks, since we cannot create links in code blocks
    $("article.pytorch-article a span.pre").each(function(e) {
      $(this).closest("a").addClass("has-code");
    });
  </script>
</body>
</html>