Namespace(arch='convnext_large_in22ft1k', batch_size=8, bottleneck_dim=256, byte_size=256, data='Both', epochs=2, iters_per_epoch=2, label=3, log='Test/', loss_function='MKMMD', lr=0.003, lr_decay=0.75, lr_gamma=0.0003, momentum=0.9, no_pool=False, non_linear=False, per_class_eval=True, phase='train', print_freq=100, random_frequencies=5, scale_parameter=1, scenario='S2T', scratch=False, seed=None, test_statistic='none', trade_off=1.0, wd=0.0005, workers=2)
Concate data
num_classes: 3
=> using model 'convnext_large_in22ft1k'
Downloading: "https://dl.fbaipublicfiles.com/convnext/convnext_large_22k_1k_224.pth" to /home/bkcs/.cache/torch/hub/checkpoints/convnext_large_22k_1k_224.pth
Epoch: [0][0/2]	Time 1.62 (1.62)	Data 0.0 (0.0)	Loss 1.52 (1.52)	Trans Loss 0.4494 (0.4494)	Cls Acc 50.0 (50.0)
Test: [  0/185]	Time  0.122 ( 0.122)	Loss 9.6799e-01 (9.6799e-01)	Acc@1 100.00 (100.00)
Test: [100/185]	Time  0.052 ( 0.053)	Loss 9.5763e-01 (1.0088e+00)	Acc@1 100.00 ( 63.37)
 * Acc@1 49.39107
 * F1 macro = 0.33885
 * F1 micro= 0.49391
 * precision macro= 0.39953
 * precision micro= 0.49391
 * recall macro = 0.32632
 * recall micro = 0.49391
global correct: 49.4
mean correct:33.8
mean IoU: 20.9
+------------------+--------------------+-------------------+
|      class       |        acc         |        iou        |
+------------------+--------------------+-------------------+
|    E-commerce    | 85.92964935302734  | 52.98218536376953 |
| Video on-demand  | 11.923076629638672 | 6.042884826660156 |
| Interactive data | 3.554502487182617  | 3.554502487182617 |
+------------------+--------------------+-------------------+
Epoch: [1][0/2]	Time 0.52 (0.52)	Data 0.0 (0.0)	Loss 1.59 (1.59)	Trans Loss 0.4658 (0.4658)	Cls Acc 37.5 (37.5)
Traceback (most recent call last):
  File "custom_dan.py", line 850, in <module>
    main(args)
  File "custom_dan.py", line 585, in main
    lr_scheduler, epoch, args)
  File "custom_dan.py", line 747, in train
    loss.backward()
  File "/home/bkcs/miniconda3/lib/python3.7/site-packages/torch/_tensor.py", line 489, in backward
    self, gradient, retain_graph, create_graph, inputs=inputs
  File "/home/bkcs/miniconda3/lib/python3.7/site-packages/torch/autograd/__init__.py", line 199, in backward
    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 9.77 GiB total capacity; 7.55 GiB already allocated; 32.00 MiB free; 8.11 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
