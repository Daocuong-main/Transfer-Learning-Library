Namespace(arch='seresnext26t_32x4d', batch_size=8, bottleneck_dim=256, byte_size=256, data='Both', epochs=2, iters_per_epoch=2, label=3, log='Test/', loss_function='MKMMD', lr=0.003, lr_decay=0.75, lr_gamma=0.0003, momentum=0.9, no_pool=False, non_linear=False, per_class_eval=True, phase='train', print_freq=100, random_frequencies=5, scale_parameter=1, scenario='S2T', scratch=False, seed=None, test_statistic='none', trade_off=1.0, wd=0.0005, workers=2)
Concate data
num_classes: 3
=> using model 'seresnext26t_32x4d'
Downloading: "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/seresnext26tn_32x4d-569cb627.pth" to /home/bkcs/.cache/torch/hub/checkpoints/seresnext26tn_32x4d-569cb627.pth
Epoch: [0][0/2]	Time 2.05 (2.05)	Data 0.0 (0.0)	Loss 1.26 (1.26)	Trans Loss 0.1618 (0.1618)	Cls Acc 37.5 (37.5)
Test: [  0/185]	Time  0.082 ( 0.082)	Loss 1.3008e+00 (1.3008e+00)	Acc@1   0.00 (  0.00)
Test: [100/185]	Time  0.011 ( 0.012)	Loss 1.3246e+00 (1.1933e+00)	Acc@1   0.00 ( 18.19)
 * Acc@1 12.78755
 * F1 macro = 0.07689
 * F1 micro= 0.12788
 * precision macro= 0.13922
 * precision micro= 0.12788
 * recall macro = 0.06343
 * recall micro = 0.12788
global correct: 12.8
mean correct:22.1
mean IoU: 7.3
+------------------+---------------------+---------------------+
|      class       |         acc         |         iou         |
+------------------+---------------------+---------------------+
|    E-commerce    | 0.12562814354896545 | 0.09225092083215714 |
| Video on-demand  |  56.153846740722656 |  16.76234245300293  |
| Interactive data |  9.952607154846191  |  5.1724138259887695 |
+------------------+---------------------+---------------------+
Epoch: [1][0/2]	Time 0.05 (0.05)	Data 0.0 (0.0)	Loss 1.26 (1.26)	Trans Loss 0.2034 (0.2034)	Cls Acc 62.5 (62.5)
Test: [  0/185]	Time  0.080 ( 0.080)	Loss 1.1981e+00 (1.1981e+00)	Acc@1   0.00 (  0.00)
Test: [100/185]	Time  0.010 ( 0.012)	Loss 1.1994e+00 (1.1090e+00)	Acc@1   0.00 ( 29.46)
 * Acc@1 17.25304
 * F1 macro = 0.11571
 * F1 micro= 0.17253
 * precision macro= 0.17621
 * precision micro= 0.17253
 * recall macro = 0.11389
 * recall micro = 0.17253
global correct: 17.3
mean correct:29.1
mean IoU: 8.2
+------------------+--------------------+--------------------+
|      class       |        acc         |        iou         |
+------------------+--------------------+--------------------+
|    E-commerce    | 5.025125503540039  | 3.527336835861206  |
| Video on-demand  | 81.53845977783203  | 20.522748947143555 |
| Interactive data | 0.7109004259109497 | 0.5617977380752563 |
+------------------+--------------------+--------------------+
Elapsed time: 8.343666315078735
best_acc1 = 17.25304
Test: [  0/185]	Time  0.080 ( 0.080)	Loss 1.1981e+00 (1.1981e+00)	Acc@1   0.00 (  0.00)
Test: [100/185]	Time  0.010 ( 0.011)	Loss 1.1994e+00 (1.1090e+00)	Acc@1   0.00 ( 29.46)
 * Acc@1 17.25304
 * F1 macro = 0.11571
 * F1 micro= 0.17253
 * precision macro= 0.17621
 * precision micro= 0.17253
 * recall macro = 0.11389
 * recall micro = 0.17253
global correct: 17.3
mean correct:29.1
mean IoU: 8.2
+------------------+--------------------+--------------------+
|      class       |        acc         |        iou         |
+------------------+--------------------+--------------------+
|    E-commerce    | 5.025125503540039  | 3.527336835861206  |
| Video on-demand  | 81.53845977783203  | 20.522748947143555 |
| Interactive data | 0.7109004259109497 | 0.5617977380752563 |
+------------------+--------------------+--------------------+
Test result below...
test_acc1 = 17.25304
F1 macro = 0.11571
F1 micro= 0.17253
precision macro= 0.17621
precision micro= 0.17253
recall macro = 0.11389
recall micro = 0.17253
avg_time = 2.65946
min_time = 2.00000
max_time = 6.00000
                  precision    recall  f1-score   support

      E-commerce    0.10582   0.05025   0.06814       796
 Video on-demand    0.21523   0.81538   0.34056       260
Interactive data    0.02609   0.00711   0.01117       422

        accuracy                        0.17253      1478
       macro avg    0.11571   0.29091   0.13996      1478
    weighted avg    0.10230   0.17253   0.09980      1478

