Namespace(arch='resnet61q', batch_size=8, bottleneck_dim=256, byte_size=256, data='Both', epochs=2, iters_per_epoch=2, label=3, log='Test/', loss_function='MKMMD', lr=0.003, lr_decay=0.75, lr_gamma=0.0003, momentum=0.9, no_pool=False, non_linear=False, per_class_eval=True, phase='train', print_freq=100, random_frequencies=5, scale_parameter=1, scenario='S2T', scratch=False, seed=None, test_statistic='none', trade_off=1.0, wd=0.0005, workers=2)
Concate data
num_classes: 3
=> using model 'resnet61q'
Downloading: "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/resnet61q_ra2-6afc536c.pth" to /home/bkcs/.cache/torch/hub/checkpoints/resnet61q_ra2-6afc536c.pth
Epoch: [0][0/2]	Time 1.72 (1.72)	Data 0.0 (0.0)	Loss 1.33 (1.33)	Trans Loss 0.2635 (0.2635)	Cls Acc 62.5 (62.5)
Test: [  0/185]	Time  0.124 ( 0.124)	Loss 1.1047e+00 (1.1047e+00)	Acc@1   0.00 (  0.00)
Test: [100/185]	Time  0.014 ( 0.015)	Loss 1.1027e+00 (1.0901e+00)	Acc@1  25.00 ( 35.02)
 * Acc@1 22.80108
 * F1 macro = 0.16220
 * F1 micro= 0.22801
 * precision macro= 0.31008
 * precision micro= 0.22801
 * recall macro = 0.13558
 * recall micro = 0.22801
global correct: 22.8
mean correct:29.9
mean IoU: 10.6
+------------------+--------------------+---------------------+
|      class       |        acc         |         iou         |
+------------------+--------------------+---------------------+
|    E-commerce    | 19.221105575561523 |  17.505720138549805 |
| Video on-demand  |        70.0        |  13.989238739013672 |
| Interactive data | 0.4739336669445038 | 0.45045045018196106 |
+------------------+--------------------+---------------------+
Epoch: [1][0/2]	Time 0.08 (0.08)	Data 0.0 (0.0)	Loss 1.23 (1.23)	Trans Loss 0.1176 (0.1176)	Cls Acc 12.5 (12.5)
Test: [  0/185]	Time  0.074 ( 0.074)	Loss 1.1063e+00 (1.1063e+00)	Acc@1   0.00 (  0.00)
Test: [100/185]	Time  0.014 ( 0.015)	Loss 1.1071e+00 (1.1145e+00)	Acc@1   0.00 ( 31.56)
 * Acc@1 38.90392
 * F1 macro = 0.25275
 * F1 micro= 0.38904
 * precision macro= 0.31099
 * precision micro= 0.38904
 * recall macro = 0.24050
 * recall micro = 0.38904
global correct: 38.9
mean correct:56.2
mean IoU: 28.2
+------------------+--------------------+-------------------+
|      class       |        acc         |        iou        |
+------------------+--------------------+-------------------+
|    E-commerce    | 3.3919599056243896 | 3.316953420639038 |
| Video on-demand  | 92.30769348144531  |  23.1436824798584 |
| Interactive data | 72.98577880859375  | 58.11320495605469 |
+------------------+--------------------+-------------------+
Elapsed time: 10.816102027893066
best_acc1 = 38.90392
Test: [  0/185]	Time  0.073 ( 0.073)	Loss 1.1063e+00 (1.1063e+00)	Acc@1   0.00 (  0.00)
Test: [100/185]	Time  0.014 ( 0.015)	Loss 1.1071e+00 (1.1145e+00)	Acc@1   0.00 ( 31.56)
 * Acc@1 38.90392
 * F1 macro = 0.25275
 * F1 micro= 0.38904
 * precision macro= 0.31099
 * precision micro= 0.38904
 * recall macro = 0.24050
 * recall micro = 0.38904
global correct: 38.9
mean correct:56.2
mean IoU: 28.2
+------------------+--------------------+-------------------+
|      class       |        acc         |        iou        |
+------------------+--------------------+-------------------+
|    E-commerce    | 3.3919599056243896 | 3.316953420639038 |
| Video on-demand  | 92.30769348144531  |  23.1436824798584 |
| Interactive data | 72.98577880859375  | 58.11320495605469 |
+------------------+--------------------+-------------------+
Test result below...
test_acc1 = 38.90392
F1 macro = 0.25275
F1 micro= 0.38904
precision macro= 0.31099
precision micro= 0.38904
recall macro = 0.24050
recall micro = 0.38904
avg_time = 3.64865
min_time = 3.00000
max_time = 7.00000
                  precision    recall  f1-score   support

      E-commerce    0.60000   0.03392   0.06421       796
 Video on-demand    0.23599   0.92308   0.37588       260
Interactive data    0.74038   0.72986   0.73508       422

        accuracy                        0.38904      1478
       macro avg    0.52546   0.56228   0.39172      1478
    weighted avg    0.57605   0.38904   0.31059      1478

