{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import csv\n",
    "import datetime\n",
    "import gc\n",
    "import os\n",
    "import os.path as osp\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import custom_utils\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import utils\n",
    "from custom_utils import plot_graph\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import newaxis\n",
    "from scipy.stats import chi2\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from tllib.alignment.dan import (ImageClassifier,\n",
    "                                 MultipleKernelMaximumMeanDiscrepancy)\n",
    "from tllib.modules.kernels import GaussianKernel\n",
    "from tllib.utils.analysis import a_distance, collect_feature\n",
    "from tllib.utils.data import ForeverDataIterator\n",
    "from tllib.utils.logger import CompleteLogger\n",
    "from tllib.utils.meter import AverageMeter, ProgressMeter\n",
    "from tllib.utils.metric import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(profile=\"full\")\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "def create_set_with_target_percentage(target_df, source_df):\n",
    "    counts = target_df['Label'].value_counts()\n",
    "    data_by_label = {}\n",
    "    for label, group in target_df.groupby('Label'):\n",
    "        data_by_label[label] = group.iloc[:, :-1] \n",
    "    sampled_rows = []\n",
    "    for i in range(counts.shape[0]):\n",
    "        data_by_label[i]['Label'] = i\n",
    "        count = len(data_by_label[i])/20 * 0/100\n",
    "        count = int(count)\n",
    "        for _ in range(count):\n",
    "            start_idx = int(data_by_label[i].sample(1).index[0]/20)*20\n",
    "            end_idx = start_idx + 20\n",
    "            sampled_group = target_df.iloc[start_idx:end_idx]\n",
    "            \n",
    "            sampled_rows.append(sampled_group)\n",
    "            data_by_label[i] = data_by_label[i].drop(sampled_group.index)\n",
    "        \n",
    "    sampled_target_df = pd.concat(sampled_rows, ignore_index=True)\n",
    "    source_df = pd.concat([source_df, sampled_target_df], ignore_index=True)\n",
    "    remaining_target_df = pd.concat([data_by_label[k] for k in range(counts.shape[0])], ignore_index=True)\n",
    "    del data_by_label,sampled_target_df,sampled_rows\n",
    "    return source_df, remaining_target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def source_target_split(df, choice, frac=0.5):\n",
    "    df_label_choice = df[df.Label == choice]\n",
    "    print(\"Selected label \" + str(choice))\n",
    "    seletected_label_3 = df_label_choice['flow_id'].drop_duplicates().sample(\n",
    "        frac=0.99)\n",
    "    seletected = df['flow_id'].drop_duplicates().sample(frac=frac)\n",
    "\n",
    "    source_select = seletected[~seletected.isin(seletected_label_3)]\n",
    "\n",
    "    source = df[df['flow_id'].isin(source_select)]\n",
    "    target = df[~df['flow_id'].isin(seletected)]\n",
    "    return source, target\n",
    "\n",
    "\n",
    "def resize_image(image, byte_size, target_size=(224, 224)):\n",
    "    if byte_size == 256:\n",
    "        target_size = (224, 224)\n",
    "    else:\n",
    "        target_size = (byte_size, byte_size)\n",
    "    return cv2.resize(image, target_size, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "\n",
    "def most_frequent(List):\n",
    "    return max(set(List), key=List.count)\n",
    "def split_data(df, frac=0.2):\n",
    "    seletected = df['flow_id'].drop_duplicates().sample(frac=frac)\n",
    "\n",
    "    val = df[df['flow_id'].isin(seletected)]\n",
    "    train = df[~df['flow_id'].isin(seletected)]\n",
    "    return train, val\n",
    "\n",
    "\n",
    "def source_target_split(df, choice, frac=0.5):\n",
    "    df_label_choice = df[df.Label == choice]\n",
    "    print(\"Selected label \" + str(choice))\n",
    "    seletected_label_3 = df_label_choice['flow_id'].drop_duplicates().sample(\n",
    "        frac=0.99)\n",
    "    seletected = df['flow_id'].drop_duplicates().sample(frac=frac)\n",
    "\n",
    "    source_select = seletected[~seletected.isin(seletected_label_3)]\n",
    "\n",
    "    source = df[df['flow_id'].isin(source_select)]\n",
    "    target = df[~df['flow_id'].isin(seletected)]\n",
    "    return source, target\n",
    "\n",
    "\n",
    "def resize_image(image, byte_size, target_size=(224, 224)):\n",
    "    if byte_size == 256:\n",
    "        target_size = (224, 224)\n",
    "    else:\n",
    "        target_size = (byte_size, byte_size)\n",
    "    return cv2.resize(image, target_size, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "def data_processing(raw_data, backbone):\n",
    "    # Get flow label\n",
    "    result = raw_data.groupby('flow_id')['Label'].apply(list).to_dict()\n",
    "    flow_label = []\n",
    "    for flow in result:\n",
    "        flow_label.append(most_frequent(result[flow]))\n",
    "    flow_label = np.array(flow_label)\n",
    "    # Reshape payloads\n",
    "    true_data = raw_data.drop('flow_id', axis=1)\n",
    "    datas = true_data.drop('Label', axis=1).to_numpy()/255\n",
    "    datas = datas.reshape(-1, 20, 256).astype('float32')\n",
    "    # print(f\"Shape of datas before resize is {datas.shape}\")\n",
    "    # Resize each image in the dataset\n",
    "    datas = np.array([resize_image(img, 256) for img in datas])\n",
    "    # print(\"before:\")\n",
    "    # print(datas.shape)\n",
    "    if 'lenet' in backbone:\n",
    "        datas = np.repeat(datas[:, :, np.newaxis, ], 1, axis=2)\n",
    "    else:\n",
    "        # print(f\"Shape of datas befor get error is: {datas.shape}\")\n",
    "        datas = np.repeat(datas[:, :, np.newaxis, ], 3, axis=2)\n",
    "    # print('middle')\n",
    "    # print(datas.shape)\n",
    "    datas = np.moveaxis(datas, 2, 1)\n",
    "    # print(\"after\")\n",
    "    # print(datas.shape)\n",
    "    final_dataset = MyDataset(datas, flow_label)\n",
    "    return final_dataset\n",
    "\n",
    "\n",
    "def remapping(df, map):\n",
    "    df_copy = df.copy()\n",
    "    df_copy['Label'] = df_copy['Label'].replace(map)\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = \"S2T\"\n",
    "subset = \"none\"\n",
    "byte_size = 256\n",
    "arch = \"resnet50\"\n",
    "batch_size = 32\n",
    "workers = 4\n",
    "percent = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concate data\n",
      "(182980, 258) (123400, 258)\n"
     ]
    }
   ],
   "source": [
    "print('Concate data')\n",
    "class_names = ['E-commerce', 'Video on-demand', 'Interactive data']\n",
    "num_classes = len(class_names)\n",
    "if scenario == \"S2T\":\n",
    "    train_source = pd.read_feather(\n",
    "        '/home/bkcs/HDD/Transfer-Learning-Library/examples/domain_adaptation/image_classification/data/concat/train_source_{}.feather'.format(byte_size))\n",
    "    if subset == \"none\":\n",
    "        train_target = pd.read_feather('/home/bkcs/HDD/Transfer-Learning-Library/examples/domain_adaptation/image_classification/data/concat/train_target_{}.feather'.format(byte_size))\n",
    "        test_raw = val_raw = pd.read_feather('/home/bkcs/HDD/Transfer-Learning-Library/examples/domain_adaptation/image_classification/data/concat/test_raw_{}.feather'.format(byte_size))\n",
    "    else:\n",
    "        train_target = pd.read_feather('/home/bkcs/HDD/Transfer-Learning-Library/examples/domain_adaptation/image_classification/data/concat/train_target_{}_{}.feather'.format(subset,byte_size))\n",
    "        test_raw = val_raw = pd.read_feather('/home/bkcs/HDD/Transfer-Learning-Library/examples/domain_adaptation/image_classification/data/concat/test_target_{}_{}.feather'.format(subset,byte_size))\n",
    "else:\n",
    "    train_target = pd.read_feather(\n",
    "        '/home/bkcs/HDD/Transfer-Learning-Library/examples/domain_adaptation/image_classification/data/concat/train_source_{}.feather'.format(byte_size))\n",
    "    train_source = pd.read_feather(\n",
    "        '/home/bkcs/HDD/Transfer-Learning-Library/examples/domain_adaptation/image_classification/data/concat/train_target_{}.feather'.format(byte_size))\n",
    "    test_raw = val_raw = pd.read_feather(\n",
    "        '/home/bkcs/HDD/Transfer-Learning-Library/examples/domain_adaptation/image_classification/data/concat/val_raw_{}.feather'.format(byte_size))\n",
    "if percent != 0:\n",
    "    train_source,train_target=create_set_with_target_percentage(train_target,train_source)\n",
    "print(train_source.shape,train_target.shape)\n",
    "train_source_dataset = data_processing(train_source, arch)\n",
    "train_target_dataset = data_processing(train_target, arch)\n",
    "val_dataset = data_processing(val_raw, arch)\n",
    "test_dataset = data_processing(test_raw, arch)\n",
    "# del train_source, train_target, val_raw, test_raw\n",
    "\n",
    "# train_source_loader = DataLoader(train_source_dataset, batch_size=batch_size,\n",
    "#                                 shuffle=True, num_workers=workers, drop_last=True)\n",
    "# train_target_loader = DataLoader(train_target_dataset, batch_size=batch_size,\n",
    "#                                 shuffle=True, num_workers=workers, drop_last=True)\n",
    "# val_loader = DataLoader(\n",
    "#     val_dataset, batch_size=batch_size, shuffle=False, num_workers=workers)\n",
    "# test_loader = DataLoader(\n",
    "#     test_dataset, batch_size=batch_size, shuffle=False, num_workers=workers)\n",
    "\n",
    "# train_source_iter = ForeverDataIterator(train_source_loader)\n",
    "# train_target_iter = ForeverDataIterator(train_target_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.MyDataset'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_source_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_source_dataset[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_source_dataset[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "print((train_source_dataset[0][0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "def save_dataset(dataset, root_dir, dataset_name):\n",
    "    images_dir = os.path.join(root_dir, dataset_name, 'images')\n",
    "    subfolders = ['ecommerce', 'video', 'interactive']\n",
    "    label_map = {0: 'ecommerce', 1: 'video', 2: 'interactive'}\n",
    "\n",
    "    # Create directories\n",
    "    for subfolder in subfolders:\n",
    "        os.makedirs(os.path.join(images_dir, subfolder), exist_ok=True)\n",
    "\n",
    "    image_list_path = os.path.join(root_dir, 'image_list', f'{dataset_name}.txt')\n",
    "    os.makedirs(os.path.dirname(image_list_path), exist_ok=True)\n",
    "\n",
    "    # Save images and create image list file\n",
    "    with open(image_list_path, 'w') as f:\n",
    "        for idx, (data, label) in enumerate(dataset):\n",
    "            if label in label_map:\n",
    "                # Convert the data to 8-bit unsigned integer\n",
    "                data = (data * 255).astype(np.uint8)\n",
    "                folder = label_map[label]\n",
    "                image_path = os.path.join(images_dir, folder, f'frame_{idx}.jpg')\n",
    "                Image.fromarray(data.transpose(1, 2, 0)).save(image_path)\n",
    "                dataset_path = os.path.join(dataset_name,\"images\" ,folder, f'frame_{idx}.jpg')\n",
    "                f.write(f'{dataset_path} {label}\\n')\n",
    "\n",
    "# Example usage:\n",
    "root_dir = '/home/bkcs/HDD/Transfer-Learning-Library/examples/domain_adaptation/image_classification/data/concat_dataset'\n",
    "\n",
    "save_dataset(train_source_dataset, root_dir, 'dataset_1')\n",
    "save_dataset(train_target_dataset, root_dir, 'dataset_2')\n",
    "save_dataset(test_dataset, root_dir, 'dataset_2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
