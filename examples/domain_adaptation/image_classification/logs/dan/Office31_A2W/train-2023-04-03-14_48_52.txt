Namespace(arch='resnet50', batch_size=32, bottleneck_dim=256, data='Office31', epochs=20, iters_per_epoch=500, log='logs/dan/Office31_A2W', lr=0.003, lr_decay=0.75, lr_gamma=0.0003, momentum=0.9, no_hflip=False, no_pool=False, non_linear=False, norm_mean=(0.485, 0.456, 0.406), norm_std=(0.229, 0.224, 0.225), per_class_eval=False, phase='train', print_freq=100, ratio=[0.75, 1.3333333333333333], resize_size=224, root='data/office31', scale=[0.08, 1.0], scratch=False, seed=1, source=['A'], target=['W'], trade_off=1.0, train_resizing='default', val_resizing='default', wd=0.0005, workers=2)
dan.py:40: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
train_transform:  Compose(
    Compose(
    ResizeImage(size=(256, 256))
    RandomResizedCrop(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear), antialias=None)
)
    RandomHorizontalFlip(p=0.5)
    ToTensor()
    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))
)
val_transform:  Compose(
    Compose(
    ResizeImage(size=(256, 256))
    CenterCrop(size=(224, 224))
)
    ToTensor()
    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))
)
=> using model 'resnet50'
/home/bkcs/miniconda3/lib/python3.7/site-packages/torchvision/models/_utils.py:253: UserWarning: Accessing the model URLs via the internal dictionary of the module is deprecated since 0.13 and may be removed in the future. Please access them via the appropriate Weights Enum instead.
  "Accessing the model URLs via the internal dictionary of the module is deprecated since 0.13 and may "
Epoch: [0][  0/500]	Time 1.82 (1.82)	Data 0.0 (0.0)	Loss 3.62 (3.62)	Trans Loss 0.0841 (0.0841)	Cls Acc 0.0 (0.0)
Epoch: [0][100/500]	Time 0.17 (0.19)	Data 0.0 (0.0)	Loss 2.98 (3.27)	Trans Loss 0.1705 (0.0530)	Cls Acc 40.6 (14.1)
Epoch: [0][200/500]	Time 0.17 (0.19)	Data 0.0 (0.0)	Loss 1.54 (2.74)	Trans Loss 0.0754 (0.0530)	Cls Acc 68.8 (30.5)
Epoch: [0][300/500]	Time 0.17 (0.18)	Data 0.0 (0.0)	Loss 1.27 (2.33)	Trans Loss 0.0573 (0.0546)	Cls Acc 56.2 (41.0)
Traceback (most recent call last):
  File "dan.py", line 264, in <module>
    main(args)
  File "dan.py", line 117, in main
    lr_scheduler, epoch, args)
  File "dan.py", line 161, in train
    x_t = x_t.to(device)
KeyboardInterrupt
