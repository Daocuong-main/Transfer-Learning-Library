Namespace(arch='resnet50', auto_augment='rand-m10-n2-mstd2', batch_size=32, bottleneck_dim=256, data='Concatdata', epochs=20, iters_per_epoch=500, log='logs/New_revision/', lr=0.001, lr_decay=0.75, lr_gamma=0.0004, momentum=0.9, no_hflip=False, no_pool=False, norm_mean=(0.485, 0.456, 0.406), norm_std=(0.229, 0.224, 0.225), per_class_eval=True, phase='train', print_freq=100, ratio=[0.75, 1.3333333333333333], resize_size=224, root='data/concat_dataset', scale=[0.5, 1.0], scratch=False, seed=0, source=['D1'], target=['D2'], threshold=0.9, trade_off=1.0, train_resizing='default', unlabeled_batch_size=96, val_resizing='default', weight_decay=0.001, workers=4)
train_source_transform:  Compose(
    Compose(
    ResizeImage(size=(256, 256))
    RandomResizedCrop(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear), antialias=None)
)
    RandomHorizontalFlip(p=0.5)
    ToTensor()
    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))
)
train_target_transform:  MultipleApply(
    Compose(
    Compose(
    ResizeImage(size=(256, 256))
    RandomResizedCrop(size=(224, 224), scale=(0.5, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear), antialias=None)
)
    RandomHorizontalFlip(p=0.5)
    ToTensor()
    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))
)
    Compose(
    Compose(
    ResizeImage(size=(256, 256))
    RandomResizedCrop(size=(224, 224), scale=(0.5, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear), antialias=None)
)
    RandomHorizontalFlip(p=0.5)
    RandAugment(n=2, ops=
	AugmentOp(name=AutoContrast, p=0.5, m=10, mstd=2.0)
	AugmentOp(name=Equalize, p=0.5, m=10, mstd=2.0)
	AugmentOp(name=Invert, p=0.5, m=10, mstd=2.0)
	AugmentOp(name=Rotate, p=0.5, m=10, mstd=2.0)
	AugmentOp(name=Posterize, p=0.5, m=10, mstd=2.0)
	AugmentOp(name=Solarize, p=0.5, m=10, mstd=2.0)
	AugmentOp(name=SolarizeAdd, p=0.5, m=10, mstd=2.0)
	AugmentOp(name=Color, p=0.5, m=10, mstd=2.0)
	AugmentOp(name=Contrast, p=0.5, m=10, mstd=2.0)
	AugmentOp(name=Brightness, p=0.5, m=10, mstd=2.0)
	AugmentOp(name=Sharpness, p=0.5, m=10, mstd=2.0)
	AugmentOp(name=ShearX, p=0.5, m=10, mstd=2.0)
	AugmentOp(name=ShearY, p=0.5, m=10, mstd=2.0)
	AugmentOp(name=TranslateXRel, p=0.5, m=10, mstd=2.0)
	AugmentOp(name=TranslateYRel, p=0.5, m=10, mstd=2.0))
    ToTensor()
    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))
)
)
val_transform:  Compose(
    Compose(
    ResizeImage(size=(256, 256))
    CenterCrop(size=(224, 224))
)
    ToTensor()
    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))
)
=> using model 'resnet50'
ImageClassifier(
  (backbone): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer4): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (fc): Linear(in_features=2048, out_features=1000, bias=True)
  )
  (pool_layer): Sequential(
    (0): AdaptiveAvgPool2d(output_size=(1, 1))
    (1): Flatten(start_dim=1, end_dim=-1)
  )
  (bottleneck): Sequential(
    (0): Linear(in_features=2048, out_features=256, bias=True)
    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (head): Linear(in_features=256, out_features=3, bias=True)
)
lr: [0.0001, 0.001, 0.001]
Epoch: [0][  0/500]	Time 17.24 (17.24)	Data  0.19 ( 0.19)	Loss   1.09 (  1.09)	Cls Loss   1.09 (  1.09)	Self Training Loss   0.00 (  0.00)	Cls Acc 40.6 (40.6)	Pseudo Label Acc 0.0 (0.0)	Pseudo Label Ratio 0.0 (0.0)
Epoch: [0][100/500]	Time 15.91 (16.00)	Data  0.02 ( 0.06)	Loss   0.89 (  0.94)	Cls Loss   0.89 (  0.94)	Self Training Loss   0.00 (  0.00)	Cls Acc 53.1 (54.0)	Pseudo Label Acc 100.0 (59.1)	Pseudo Label Ratio 0.0 (0.2)
Epoch: [0][200/500]	Time 16.00 (15.99)	Data  0.01 ( 0.06)	Loss   0.93 (  0.89)	Cls Loss   0.92 (  0.89)	Self Training Loss   0.02 (  0.00)	Cls Acc 46.9 (57.7)	Pseudo Label Acc 66.7 (71.7)	Pseudo Label Ratio 3.1 (0.9)
Epoch: [0][300/500]	Time 17.08 (15.99)	Data  0.64 ( 0.06)	Loss   0.89 (  0.87)	Cls Loss   0.87 (  0.86)	Self Training Loss   0.02 (  0.01)	Cls Acc 53.1 (59.4)	Pseudo Label Acc 75.0 (72.8)	Pseudo Label Ratio 4.2 (2.1)
Epoch: [0][400/500]	Time 15.84 (15.98)	Data  0.01 ( 0.06)	Loss   0.75 (  0.85)	Cls Loss   0.74 (  0.84)	Self Training Loss   0.01 (  0.01)	Cls Acc 65.6 (60.9)	Pseudo Label Acc 80.0 (70.1)	Pseudo Label Ratio 5.2 (3.1)
Test: [ 0/47]	Time  1.334 ( 1.334)	Loss 8.6349e-01 (8.6349e-01)	Acc@1  56.25 ( 56.25)
 * Acc@1 47.90257
 * F1 macro = 0.27460
 * F1 micro= 0.47903
 * precision macro= 0.40744
 * precision micro= 0.47903
 * recall macro = 0.24491
 * recall micro = 0.47903
global correct: 47.9
mean correct:47.7
mean IoU: 27.0
+------------------+-------------------+--------------------+
|      class       |        acc        |        iou         |
+------------------+-------------------+--------------------+
|    E-commerce    |  60.4271354675293 | 49.333335876464844 |
| Video on-demand  | 75.38461303710938 | 25.42152976989746  |
| Interactive data | 7.345971584320068 | 6.175299167633057  |
+------------------+-------------------+--------------------+
lr: [8.721959494934213e-05, 0.0008721959494934213, 0.0008721959494934213]
Epoch: [1][  0/500]	Time 16.37 (16.37)	Data  0.00 ( 0.00)	Loss   0.79 (  0.79)	Cls Loss   0.74 (  0.74)	Self Training Loss   0.05 (  0.05)	Cls Acc 71.9 (71.9)	Pseudo Label Acc 44.4 (44.4)	Pseudo Label Ratio 9.4 (9.4)
Epoch: [1][100/500]	Time 17.23 (15.98)	Data  0.71 ( 0.07)	Loss   0.69 (  0.78)	Cls Loss   0.65 (  0.74)	Self Training Loss   0.04 (  0.04)	Cls Acc 78.1 (66.3)	Pseudo Label Acc 62.5 (70.2)	Pseudo Label Ratio 16.7 (11.3)
Epoch: [1][200/500]	Time 16.08 (15.98)	Data  0.01 ( 0.06)	Loss   0.80 (  0.77)	Cls Loss   0.76 (  0.73)	Self Training Loss   0.05 (  0.05)	Cls Acc 62.5 (67.6)	Pseudo Label Acc 88.2 (72.9)	Pseudo Label Ratio 17.7 (13.3)
Epoch: [1][300/500]	Time 16.15 (15.98)	Data  0.02 ( 0.06)	Loss   0.55 (  0.77)	Cls Loss   0.51 (  0.73)	Self Training Loss   0.04 (  0.04)	Cls Acc 78.1 (67.7)	Pseudo Label Acc 60.0 (71.9)	Pseudo Label Ratio 15.6 (13.6)
Epoch: [1][400/500]	Time 17.23 (15.99)	Data  0.71 ( 0.06)	Loss   0.57 (  0.76)	Cls Loss   0.51 (  0.72)	Self Training Loss   0.06 (  0.05)	Cls Acc 81.2 (68.1)	Pseudo Label Acc 56.2 (71.5)	Pseudo Label Ratio 16.7 (14.9)
Test: [ 0/47]	Time  1.221 ( 1.221)	Loss 4.8174e-01 (4.8174e-01)	Acc@1  71.88 ( 71.88)
 * Acc@1 56.02165
 * F1 macro = 0.32192
 * F1 micro= 0.56022
 * precision macro= 0.42573
 * precision micro= 0.56022
 * recall macro = 0.29074
 * recall micro = 0.56022
global correct: 56.0
mean correct:53.9
mean IoU: 35.7
+------------------+-------------------+--------------------+
|      class       |        acc        |        iou         |
+------------------+-------------------+--------------------+
|    E-commerce    |  68.0904541015625 |  61.1048469543457  |
| Video on-demand  | 67.69230651855469 |  23.4354190826416  |
| Interactive data | 26.06635093688965 | 22.448978424072266 |
+------------------+-------------------+--------------------+
lr: [7.769695042409124e-05, 0.0007769695042409123, 0.0007769695042409123]
Epoch: [2][  0/500]	Time 16.04 (16.04)	Data  0.01 ( 0.01)	Loss   0.59 (  0.59)	Cls Loss   0.53 (  0.53)	Self Training Loss   0.06 (  0.06)	Cls Acc 78.1 (78.1)	Pseudo Label Acc 65.2 (65.2)	Pseudo Label Ratio 24.0 (24.0)
Epoch: [2][100/500]	Time 15.79 (16.02)	Data  0.01 ( 0.06)	Loss   0.93 (  0.74)	Cls Loss   0.83 (  0.68)	Self Training Loss   0.11 (  0.06)	Cls Acc 65.6 (71.1)	Pseudo Label Acc 85.7 (71.3)	Pseudo Label Ratio 29.2 (22.6)
Epoch: [2][200/500]	Time 17.28 (16.03)	Data  0.70 ( 0.06)	Loss   0.82 (  0.74)	Cls Loss   0.78 (  0.67)	Self Training Loss   0.04 (  0.06)	Cls Acc 59.4 (70.6)	Pseudo Label Acc 82.4 (70.6)	Pseudo Label Ratio 17.7 (23.0)
Epoch: [2][300/500]	Time 15.97 (16.02)	Data  0.01 ( 0.06)	Loss   0.67 (  0.72)	Cls Loss   0.60 (  0.66)	Self Training Loss   0.06 (  0.06)	Cls Acc 75.0 (71.1)	Pseudo Label Acc 84.0 (70.6)	Pseudo Label Ratio 26.0 (23.5)
Epoch: [2][400/500]	Time 15.83 (16.03)	Data  0.01 ( 0.06)	Loss   0.58 (  0.72)	Cls Loss   0.53 (  0.66)	Self Training Loss   0.05 (  0.06)	Cls Acc 84.4 (71.0)	Pseudo Label Acc 82.6 (71.2)	Pseudo Label Ratio 24.0 (24.0)
Test: [ 0/47]	Time  1.278 ( 1.278)	Loss 5.7768e-01 (5.7768e-01)	Acc@1  81.25 ( 81.25)
 * Acc@1 69.62111
 * F1 macro = 0.38770
 * F1 micro= 0.69621
 * precision macro= 0.45183
 * precision micro= 0.69621
 * recall macro = 0.35942
 * recall micro = 0.69621
global correct: 69.6
mean correct:68.4
mean IoU: 51.6
+------------------+--------------------+--------------------+
|      class       |        acc         |        iou         |
+------------------+--------------------+--------------------+
|    E-commerce    | 73.24120330810547  | 66.70480346679688  |
| Video on-demand  | 68.46154022216797  | 30.220714569091797 |
| Interactive data | 63.507110595703125 | 57.75862503051758  |
+------------------+--------------------+--------------------+
lr: [7.029266564879362e-05, 0.0007029266564879363, 0.0007029266564879363]
Epoch: [3][  0/500]	Time 17.33 (17.33)	Data  0.72 ( 0.72)	Loss   0.58 (  0.58)	Cls Loss   0.51 (  0.51)	Self Training Loss   0.07 (  0.07)	Cls Acc 78.1 (78.1)	Pseudo Label Acc 80.0 (80.0)	Pseudo Label Ratio 31.2 (31.2)
Epoch: [3][100/500]	Time 15.93 (16.06)	Data  0.02 ( 0.06)	Loss   0.72 (  0.67)	Cls Loss   0.68 (  0.60)	Self Training Loss   0.05 (  0.07)	Cls Acc 78.1 (74.1)	Pseudo Label Acc 77.8 (72.1)	Pseudo Label Ratio 28.1 (28.1)
Epoch: [3][200/500]	Time 15.97 (16.06)	Data  0.01 ( 0.06)	Loss   0.56 (  0.69)	Cls Loss   0.53 (  0.62)	Self Training Loss   0.03 (  0.07)	Cls Acc 71.9 (73.7)	Pseudo Label Acc 84.6 (71.1)	Pseudo Label Ratio 27.1 (28.6)
Epoch: [3][300/500]	Time 17.03 (16.05)	Data  0.72 ( 0.06)	Loss   0.56 (  0.68)	Cls Loss   0.50 (  0.61)	Self Training Loss   0.06 (  0.07)	Cls Acc 81.2 (73.8)	Pseudo Label Acc 60.9 (70.3)	Pseudo Label Ratio 24.0 (28.7)
Epoch: [3][400/500]	Time 15.93 (16.04)	Data  0.01 ( 0.06)	Loss   0.63 (  0.68)	Cls Loss   0.59 (  0.61)	Self Training Loss   0.04 (  0.07)	Cls Acc 75.0 (74.1)	Pseudo Label Acc 74.2 (70.1)	Pseudo Label Ratio 32.3 (29.5)
Test: [ 0/47]	Time  1.342 ( 1.342)	Loss 5.1703e-01 (5.1703e-01)	Acc@1  81.25 ( 81.25)
 * Acc@1 62.92287
 * F1 macro = 0.38979
 * F1 micro= 0.62923
 * precision macro= 0.48015
 * precision micro= 0.62923
 * recall macro = 0.35563
 * recall micro = 0.62923
global correct: 62.9
mean correct:61.9
mean IoU: 43.6
+------------------+-------------------+--------------------+
|      class       |        acc        |        iou         |
+------------------+-------------------+--------------------+
|    E-commerce    | 70.97989654541016 | 65.31791687011719  |
| Video on-demand  | 73.46154022216797 | 26.939350128173828 |
| Interactive data | 41.23222732543945 | 38.495574951171875 |
+------------------+-------------------+--------------------+
lr: [6.434956584934828e-05, 0.0006434956584934828, 0.0006434956584934828]
Epoch: [4][  0/500]	Time 16.52 (16.52)	Data  0.01 ( 0.01)	Loss   0.58 (  0.58)	Cls Loss   0.56 (  0.56)	Self Training Loss   0.02 (  0.02)	Cls Acc 71.9 (71.9)	Pseudo Label Acc 75.8 (75.8)	Pseudo Label Ratio 34.4 (34.4)
Epoch: [4][100/500]	Time 17.25 (16.07)	Data  0.69 ( 0.06)	Loss   0.57 (  0.67)	Cls Loss   0.53 (  0.60)	Self Training Loss   0.04 (  0.07)	Cls Acc 78.1 (74.7)	Pseudo Label Acc 57.6 (70.6)	Pseudo Label Ratio 34.4 (31.6)
Epoch: [4][200/500]	Time 16.13 (16.05)	Data  0.01 ( 0.06)	Loss   0.61 (  0.66)	Cls Loss   0.55 (  0.58)	Self Training Loss   0.06 (  0.07)	Cls Acc 68.8 (75.0)	Pseudo Label Acc 76.7 (70.9)	Pseudo Label Ratio 31.2 (32.5)
Epoch: [4][300/500]	Time 16.01 (16.05)	Data  0.01 ( 0.06)	Loss   0.65 (  0.66)	Cls Loss   0.61 (  0.59)	Self Training Loss   0.04 (  0.08)	Cls Acc 71.9 (75.0)	Pseudo Label Acc 71.0 (71.3)	Pseudo Label Ratio 32.3 (33.3)
Epoch: [4][400/500]	Time 17.33 (16.06)	Data  0.72 ( 0.06)	Loss   0.86 (  0.66)	Cls Loss   0.80 (  0.58)	Self Training Loss   0.06 (  0.08)	Cls Acc 62.5 (75.3)	Pseudo Label Acc 75.0 (71.4)	Pseudo Label Ratio 33.3 (33.7)
Test: [ 0/47]	Time  1.291 ( 1.291)	Loss 5.5035e-01 (5.5035e-01)	Acc@1  81.25 ( 81.25)
 * Acc@1 74.28958
 * F1 macro = 0.43093
 * F1 micro= 0.74290
 * precision macro= 0.48354
 * precision micro= 0.74290
 * recall macro = 0.40827
 * recall micro = 0.74290
global correct: 74.3
mean correct:74.1
mean IoU: 58.3
+------------------+-------------------+-------------------+
|      class       |        acc        |        iou        |
+------------------+-------------------+-------------------+
|    E-commerce    | 73.74372100830078 |  67.7047348022461 |
| Video on-demand  | 71.92308044433594 | 34.18647003173828 |
| Interactive data | 76.77725219726562 | 72.97296905517578 |
+------------------+-------------------+-------------------+
lr: [5.946035575013605e-05, 0.0005946035575013605, 0.0005946035575013605]
Epoch: [5][  0/500]	Time 16.07 (16.07)	Data  0.00 ( 0.00)	Loss   0.68 (  0.68)	Cls Loss   0.64 (  0.64)	Self Training Loss   0.04 (  0.04)	Cls Acc 68.8 (68.8)	Pseudo Label Acc 71.4 (71.4)	Pseudo Label Ratio 36.5 (36.5)
Epoch: [5][100/500]	Time 16.12 (16.09)	Data  0.01 ( 0.07)	Loss   0.95 (  0.64)	Cls Loss   0.90 (  0.56)	Self Training Loss   0.05 (  0.08)	Cls Acc 62.5 (76.4)	Pseudo Label Acc 73.7 (69.4)	Pseudo Label Ratio 39.6 (36.5)
Epoch: [5][200/500]	Time 17.20 (16.07)	Data  0.72 ( 0.06)	Loss   0.72 (  0.65)	Cls Loss   0.67 (  0.57)	Self Training Loss   0.05 (  0.08)	Cls Acc 71.9 (76.2)	Pseudo Label Acc 80.0 (71.1)	Pseudo Label Ratio 36.5 (36.1)
Epoch: [5][300/500]	Time 15.83 (16.06)	Data  0.02 ( 0.06)	Loss   0.51 (  0.64)	Cls Loss   0.43 (  0.56)	Self Training Loss   0.09 (  0.09)	Cls Acc 84.4 (76.8)	Pseudo Label Acc 53.7 (71.3)	Pseudo Label Ratio 42.7 (35.9)
Epoch: [5][400/500]	Time 16.05 (16.05)	Data  0.01 ( 0.06)	Loss   0.73 (  0.64)	Cls Loss   0.56 (  0.56)	Self Training Loss   0.17 (  0.08)	Cls Acc 75.0 (76.7)	Pseudo Label Acc 64.9 (71.4)	Pseudo Label Ratio 38.5 (36.0)
Test: [ 0/47]	Time  1.247 ( 1.247)	Loss 6.5039e-01 (6.5039e-01)	Acc@1  81.25 ( 81.25)
 * Acc@1 76.11637
 * F1 macro = 0.43724
 * F1 micro= 0.76116
 * precision macro= 0.48317
 * precision micro= 0.76116
 * recall macro = 0.41569
 * recall micro = 0.76116
global correct: 76.1
mean correct:77.6
mean IoU: 61.1
+------------------+-------------------+--------------------+
|      class       |        acc        |        iou         |
+------------------+-------------------+--------------------+
|    E-commerce    | 71.60803985595703 |  66.8229751586914  |
| Video on-demand  | 76.92308044433594 | 38.167938232421875 |
| Interactive data | 84.12322235107422 | 78.19383239746094  |
+------------------+-------------------+--------------------+
lr: [5.535833116504122e-05, 0.0005535833116504121, 0.0005535833116504121]
Epoch: [6][  0/500]	Time 16.91 (16.91)	Data  0.71 ( 0.71)	Loss   0.80 (  0.80)	Cls Loss   0.62 (  0.62)	Self Training Loss   0.19 (  0.19)	Cls Acc 68.8 (68.8)	Pseudo Label Acc 70.0 (70.0)	Pseudo Label Ratio 52.1 (52.1)
Epoch: [6][100/500]	Time 15.99 (16.03)	Data  0.02 ( 0.06)	Loss   0.82 (  0.65)	Cls Loss   0.72 (  0.57)	Self Training Loss   0.10 (  0.08)	Cls Acc 62.5 (75.5)	Pseudo Label Acc 75.6 (73.8)	Pseudo Label Ratio 42.7 (38.1)
Epoch: [6][200/500]	Time 15.97 (16.04)	Data  0.02 ( 0.06)	Loss   0.44 (  0.63)	Cls Loss   0.33 (  0.55)	Self Training Loss   0.10 (  0.08)	Cls Acc 87.5 (76.7)	Pseudo Label Acc 67.7 (73.8)	Pseudo Label Ratio 32.3 (38.5)
Epoch: [6][300/500]	Time 17.32 (16.05)	Data  0.72 ( 0.06)	Loss   0.80 (  0.64)	Cls Loss   0.68 (  0.55)	Self Training Loss   0.13 (  0.09)	Cls Acc 68.8 (76.7)	Pseudo Label Acc 55.6 (73.2)	Pseudo Label Ratio 37.5 (38.4)
Epoch: [6][400/500]	Time 16.14 (16.04)	Data  0.01 ( 0.06)	Loss   0.51 (  0.64)	Cls Loss   0.47 (  0.55)	Self Training Loss   0.04 (  0.09)	Cls Acc 87.5 (76.9)	Pseudo Label Acc 74.4 (73.8)	Pseudo Label Ratio 40.6 (38.2)
Test: [ 0/47]	Time  1.356 ( 1.356)	Loss 6.3116e-01 (6.3116e-01)	Acc@1  81.25 ( 81.25)
 * Acc@1 59.06631
 * F1 macro = 0.34071
 * F1 micro= 0.59066
 * precision macro= 0.43298
 * precision micro= 0.59066
 * recall macro = 0.31681
 * recall micro = 0.59066
global correct: 59.1
mean correct:57.4
mean IoU: 37.2
+------------------+-------------------+-------------------+
|      class       |        acc        |        iou        |
+------------------+-------------------+-------------------+
|    E-commerce    | 72.48743438720703 | 51.65622329711914 |
| Video on-demand  | 76.92308044433594 | 38.75968933105469 |
| Interactive data | 22.74881362915039 | 21.33333396911621 |
+------------------+-------------------+-------------------+
lr: [5.186108144070653e-05, 0.0005186108144070653, 0.0005186108144070653]
Epoch: [7][  0/500]	Time 16.69 (16.69)	Data  0.01 ( 0.01)	Loss   0.55 (  0.55)	Cls Loss   0.49 (  0.49)	Self Training Loss   0.06 (  0.06)	Cls Acc 75.0 (75.0)	Pseudo Label Acc 81.1 (81.1)	Pseudo Label Ratio 38.5 (38.5)
Epoch: [7][100/500]	Time 17.23 (16.06)	Data  0.72 ( 0.06)	Loss   0.46 (  0.61)	Cls Loss   0.42 (  0.53)	Self Training Loss   0.04 (  0.09)	Cls Acc 84.4 (78.6)	Pseudo Label Acc 75.8 (70.9)	Pseudo Label Ratio 34.4 (35.6)
Epoch: [7][200/500]	Time 16.13 (16.06)	Data  0.01 ( 0.06)	Loss   0.65 (  0.61)	Cls Loss   0.60 (  0.52)	Self Training Loss   0.04 (  0.09)	Cls Acc 71.9 (78.2)	Pseudo Label Acc 67.6 (71.1)	Pseudo Label Ratio 35.4 (36.1)
Epoch: [7][300/500]	Time 16.17 (16.11)	Data  0.01 ( 0.06)	Loss   0.52 (  0.62)	Cls Loss   0.44 (  0.53)	Self Training Loss   0.09 (  0.09)	Cls Acc 81.2 (78.2)	Pseudo Label Acc 73.3 (71.3)	Pseudo Label Ratio 31.2 (37.1)
Epoch: [7][400/500]	Time 17.46 (16.14)	Data  0.73 ( 0.06)	Loss   0.79 (  0.62)	Cls Loss   0.69 (  0.53)	Self Training Loss   0.10 (  0.09)	Cls Acc 62.5 (77.9)	Pseudo Label Acc 71.8 (71.6)	Pseudo Label Ratio 40.6 (37.1)
Test: [ 0/47]	Time  1.355 ( 1.355)	Loss 5.3723e-01 (5.3723e-01)	Acc@1  84.38 ( 84.38)
 * Acc@1 74.28958
 * F1 macro = 0.39355
 * F1 micro= 0.74290
 * precision macro= 0.44149
 * precision micro= 0.74290
 * recall macro = 0.37224
 * recall micro = 0.74290
global correct: 74.3
mean correct:74.8
mean IoU: 58.3
+------------------+-------------------+-------------------+
|      class       |        acc        |        iou        |
+------------------+-------------------+-------------------+
|    E-commerce    | 72.98995208740234 | 64.69933319091797 |
| Video on-demand  |        75.0       |  37.937744140625  |
| Interactive data | 76.30331420898438 | 72.19731140136719 |
+------------------+-------------------+-------------------+
lr: [4.883936278745637e-05, 0.0004883936278745637, 0.0004883936278745637]
Epoch: [8][  0/500]	Time 16.81 (16.81)	Data  0.01 ( 0.01)	Loss   0.38 (  0.38)	Cls Loss   0.26 (  0.26)	Self Training Loss   0.12 (  0.12)	Cls Acc 90.6 (90.6)	Pseudo Label Acc 76.3 (76.3)	Pseudo Label Ratio 39.6 (39.6)
Epoch: [8][100/500]	Time 15.72 (16.22)	Data  0.01 ( 0.06)	Loss   0.49 (  0.61)	Cls Loss   0.38 (  0.51)	Self Training Loss   0.11 (  0.10)	Cls Acc 84.4 (79.5)	Pseudo Label Acc 78.9 (74.2)	Pseudo Label Ratio 39.6 (39.2)
Epoch: [8][200/500]	Time 17.17 (16.20)	Data  0.73 ( 0.06)	Loss   0.62 (  0.61)	Cls Loss   0.52 (  0.51)	Self Training Loss   0.09 (  0.10)	Cls Acc 75.0 (79.0)	Pseudo Label Acc 75.0 (74.4)	Pseudo Label Ratio 45.8 (39.5)
Epoch: [8][300/500]	Time 15.93 (16.20)	Data  0.02 ( 0.06)	Loss   0.69 (  0.61)	Cls Loss   0.58 (  0.51)	Self Training Loss   0.11 (  0.10)	Cls Acc 71.9 (79.1)	Pseudo Label Acc 78.0 (74.4)	Pseudo Label Ratio 42.7 (39.7)
Epoch: [8][400/500]	Time 16.03 (16.20)	Data  0.01 ( 0.06)	Loss   0.50 (  0.61)	Cls Loss   0.36 (  0.51)	Self Training Loss   0.14 (  0.10)	Cls Acc 78.1 (78.9)	Pseudo Label Acc 75.0 (74.3)	Pseudo Label Ratio 37.5 (39.4)
Test: [ 0/47]	Time  1.353 ( 1.353)	Loss 6.0429e-01 (6.0429e-01)	Acc@1  81.25 ( 81.25)
 * Acc@1 75.16915
 * F1 macro = 0.40362
 * F1 micro= 0.75169
 * precision macro= 0.44902
 * precision micro= 0.75169
 * recall macro = 0.38093
 * recall micro = 0.75169
global correct: 75.2
mean correct:76.6
mean IoU: 60.1
+------------------+-------------------+--------------------+
|      class       |        acc        |        iou         |
+------------------+-------------------+--------------------+
|    E-commerce    | 71.10552978515625 | 64.46469116210938  |
| Video on-demand  | 77.30769348144531 | 38.579654693603516 |
| Interactive data | 81.51658630371094 | 77.13004302978516  |
+------------------+-------------------+--------------------+
lr: [4.619888312917149e-05, 0.00046198883129171486, 0.00046198883129171486]
Epoch: [9][  0/500]	Time 17.57 (17.57)	Data  0.68 ( 0.68)	Loss   0.69 (  0.69)	Cls Loss   0.55 (  0.55)	Self Training Loss   0.14 (  0.14)	Cls Acc 68.8 (68.8)	Pseudo Label Acc 78.6 (78.6)	Pseudo Label Ratio 43.8 (43.8)
Epoch: [9][100/500]	Time 15.89 (16.22)	Data  0.02 ( 0.07)	Loss   0.48 (  0.59)	Cls Loss   0.44 (  0.49)	Self Training Loss   0.04 (  0.10)	Cls Acc 84.4 (79.8)	Pseudo Label Acc 63.6 (74.3)	Pseudo Label Ratio 34.4 (40.1)
Epoch: [9][200/500]	Time 15.92 (16.20)	Data  0.02 ( 0.07)	Loss   0.56 (  0.60)	Cls Loss   0.43 (  0.50)	Self Training Loss   0.14 (  0.10)	Cls Acc 84.4 (79.3)	Pseudo Label Acc 62.5 (73.9)	Pseudo Label Ratio 33.3 (39.4)
Epoch: [9][300/500]	Time 17.14 (16.15)	Data  0.72 ( 0.06)	Loss   0.76 (  0.61)	Cls Loss   0.65 (  0.51)	Self Training Loss   0.10 (  0.10)	Cls Acc 78.1 (78.7)	Pseudo Label Acc 84.1 (74.6)	Pseudo Label Ratio 45.8 (39.7)
Epoch: [9][400/500]	Time 15.90 (16.12)	Data  0.01 ( 0.06)	Loss   0.42 (  0.62)	Cls Loss   0.35 (  0.52)	Self Training Loss   0.07 (  0.09)	Cls Acc 87.5 (78.0)	Pseudo Label Acc 74.3 (74.9)	Pseudo Label Ratio 36.5 (39.0)
Test: [ 0/47]	Time  1.368 ( 1.368)	Loss 5.4051e-01 (5.4051e-01)	Acc@1  84.38 ( 84.38)
 * Acc@1 73.00406
 * F1 macro = 0.42457
 * F1 micro= 0.73004
 * precision macro= 0.47815
 * precision micro= 0.73004
 * recall macro = 0.39912
 * recall micro = 0.73004
global correct: 73.0
mean correct:72.5
mean IoU: 56.2
+------------------+-------------------+-------------------+
|      class       |        acc        |        iou        |
+------------------+-------------------+-------------------+
|    E-commerce    | 75.12562561035156 | 68.26483917236328 |
| Video on-demand  | 73.84615325927734 | 33.92226028442383 |
| Interactive data | 68.48341369628906 | 66.43678283691406 |
+------------------+-------------------+-------------------+
lr: [4.3869133765083086e-05, 0.0004386913376508308, 0.0004386913376508308]
Epoch: [10][  0/500]	Time 16.43 (16.43)	Data  0.00 ( 0.00)	Loss   0.70 (  0.70)	Cls Loss   0.54 (  0.54)	Self Training Loss   0.16 (  0.16)	Cls Acc 78.1 (78.1)	Pseudo Label Acc 73.7 (73.7)	Pseudo Label Ratio 39.6 (39.6)
Epoch: [10][100/500]	Time 17.20 (16.06)	Data  0.72 ( 0.06)	Loss   0.75 (  0.59)	Cls Loss   0.64 (  0.50)	Self Training Loss   0.11 (  0.09)	Cls Acc 71.9 (79.6)	Pseudo Label Acc 76.5 (75.5)	Pseudo Label Ratio 35.4 (39.4)
Epoch: [10][200/500]	Time 16.10 (16.05)	Data  0.01 ( 0.06)	Loss   0.67 (  0.60)	Cls Loss   0.58 (  0.51)	Self Training Loss   0.09 (  0.09)	Cls Acc 78.1 (78.9)	Pseudo Label Acc 80.0 (75.4)	Pseudo Label Ratio 31.2 (39.3)
Epoch: [10][300/500]	Time 15.99 (16.06)	Data  0.01 ( 0.06)	Loss   0.70 (  0.60)	Cls Loss   0.61 (  0.51)	Self Training Loss   0.08 (  0.09)	Cls Acc 75.0 (79.0)	Pseudo Label Acc 83.3 (75.5)	Pseudo Label Ratio 37.5 (38.9)
Epoch: [10][400/500]	Time 17.15 (16.06)	Data  0.72 ( 0.06)	Loss   0.74 (  0.60)	Cls Loss   0.69 (  0.51)	Self Training Loss   0.06 (  0.10)	Cls Acc 71.9 (79.2)	Pseudo Label Acc 69.4 (74.9)	Pseudo Label Ratio 37.5 (38.8)
Test: [ 0/47]	Time  1.228 ( 1.228)	Loss 5.5659e-01 (5.5659e-01)	Acc@1  81.25 ( 81.25)
 * Acc@1 57.91610
 * F1 macro = 0.33642
 * F1 micro= 0.57916
 * precision macro= 0.44397
 * precision micro= 0.57916
 * recall macro = 0.30571
 * recall micro = 0.57916
global correct: 57.9
mean correct:56.4
mean IoU: 37.2
+------------------+--------------------+--------------------+
|      class       |        acc         |        iou         |
+------------------+--------------------+--------------------+
|    E-commerce    | 70.72864532470703  | 65.38908386230469  |
| Video on-demand  | 75.38461303710938  |  25.2252254486084  |
| Interactive data | 22.985782623291016 | 20.995670318603516 |
+------------------+--------------------+--------------------+
lr: [4.179626906102638e-05, 0.00041796269061026377, 0.00041796269061026377]
Epoch: [11][  0/500]	Time 16.63 (16.63)	Data  0.00 ( 0.00)	Loss   0.52 (  0.52)	Cls Loss   0.45 (  0.45)	Self Training Loss   0.07 (  0.07)	Cls Acc 84.4 (84.4)	Pseudo Label Acc 74.2 (74.2)	Pseudo Label Ratio 32.3 (32.3)
Epoch: [11][100/500]	Time 15.90 (16.08)	Data  0.01 ( 0.06)	Loss   1.00 (  0.58)	Cls Loss   0.91 (  0.49)	Self Training Loss   0.09 (  0.10)	Cls Acc 65.6 (80.9)	Pseudo Label Acc 77.8 (76.3)	Pseudo Label Ratio 37.5 (38.8)
Epoch: [11][200/500]	Time 17.70 (16.08)	Data  1.05 ( 0.07)	Loss   0.44 (  0.59)	Cls Loss   0.34 (  0.49)	Self Training Loss   0.10 (  0.10)	Cls Acc 84.4 (80.2)	Pseudo Label Acc 67.6 (76.0)	Pseudo Label Ratio 38.5 (38.9)
Epoch: [11][300/500]	Time 15.98 (16.07)	Data  0.02 ( 0.06)	Loss   0.68 (  0.60)	Cls Loss   0.56 (  0.50)	Self Training Loss   0.11 (  0.10)	Cls Acc 71.9 (79.7)	Pseudo Label Acc 71.4 (75.8)	Pseudo Label Ratio 36.5 (38.9)
Epoch: [11][400/500]	Time 15.94 (16.07)	Data  0.01 ( 0.06)	Loss   0.69 (  0.59)	Cls Loss   0.64 (  0.50)	Self Training Loss   0.05 (  0.10)	Cls Acc 75.0 (79.8)	Pseudo Label Acc 65.7 (75.7)	Pseudo Label Ratio 36.5 (38.9)
Test: [ 0/47]	Time  1.348 ( 1.348)	Loss 5.4851e-01 (5.4851e-01)	Acc@1  81.25 ( 81.25)
 * Acc@1 58.79567
 * F1 macro = 0.32887
 * F1 micro= 0.58796
 * precision macro= 0.42061
 * precision micro= 0.58796
 * recall macro = 0.29989
 * recall micro = 0.58796
global correct: 58.8
mean correct:57.8
mean IoU: 38.1
+------------------+--------------------+--------------------+
|      class       |        acc         |        iou         |
+------------------+--------------------+--------------------+
|    E-commerce    | 70.22613525390625  | 64.03207397460938  |
| Video on-demand  | 77.30769348144531  | 26.728721618652344 |
| Interactive data | 25.829383850097656 | 23.593074798583984 |
+------------------+--------------------+--------------------+
lr: [3.993841378579542e-05, 0.00039938413785795413, 0.00039938413785795413]
Epoch: [12][  0/500]	Time 17.40 (17.40)	Data  0.62 ( 0.62)	Loss   0.35 (  0.35)	Cls Loss   0.29 (  0.29)	Self Training Loss   0.07 (  0.07)	Cls Acc 93.8 (93.8)	Pseudo Label Acc 76.5 (76.5)	Pseudo Label Ratio 35.4 (35.4)
Epoch: [12][100/500]	Time 16.38 (16.18)	Data  0.01 ( 0.06)	Loss   0.71 (  0.59)	Cls Loss   0.59 (  0.49)	Self Training Loss   0.13 (  0.10)	Cls Acc 71.9 (80.0)	Pseudo Label Acc 82.9 (75.5)	Pseudo Label Ratio 42.7 (40.1)
Epoch: [12][200/500]	Time 16.16 (16.24)	Data  0.01 ( 0.06)	Loss   0.76 (  0.60)	Cls Loss   0.64 (  0.50)	Self Training Loss   0.12 (  0.10)	Cls Acc 84.4 (79.4)	Pseudo Label Acc 67.6 (76.1)	Pseudo Label Ratio 35.4 (40.0)
Epoch: [12][300/500]	Time 17.22 (16.23)	Data  0.74 ( 0.07)	Loss   0.54 (  0.59)	Cls Loss   0.50 (  0.49)	Self Training Loss   0.04 (  0.10)	Cls Acc 75.0 (79.8)	Pseudo Label Acc 75.7 (76.3)	Pseudo Label Ratio 38.5 (39.9)
Epoch: [12][400/500]	Time 16.30 (16.23)	Data  0.02 ( 0.06)	Loss   0.72 (  0.59)	Cls Loss   0.64 (  0.49)	Self Training Loss   0.08 (  0.10)	Cls Acc 78.1 (79.8)	Pseudo Label Acc 75.6 (76.5)	Pseudo Label Ratio 42.7 (40.0)
Test: [ 0/47]	Time  1.299 ( 1.299)	Loss 6.5394e-01 (6.5394e-01)	Acc@1  81.25 ( 81.25)
 * Acc@1 58.72801
 * F1 macro = 0.34259
 * F1 micro= 0.58728
 * precision macro= 0.44973
 * precision micro= 0.58728
 * recall macro = 0.30575
 * recall micro = 0.58728
global correct: 58.7
mean correct:59.0
mean IoU: 38.7
+------------------+--------------------+--------------------+
|      class       |        acc         |        iou         |
+------------------+--------------------+--------------------+
|    E-commerce    |  67.9648208618164  | 64.17556762695312  |
| Video on-demand  | 81.92308044433594  | 27.377891540527344 |
| Interactive data | 27.014217376708984 | 24.411134719848633 |
+------------------+--------------------+--------------------+
lr: [3.826248077769055e-05, 0.00038262480777690545, 0.00038262480777690545]
Epoch: [13][  0/500]	Time 16.84 (16.84)	Data  0.01 ( 0.01)	Loss   0.66 (  0.66)	Cls Loss   0.55 (  0.55)	Self Training Loss   0.11 (  0.11)	Cls Acc 84.4 (84.4)	Pseudo Label Acc 71.1 (71.1)	Pseudo Label Ratio 39.6 (39.6)
Epoch: [13][100/500]	Time 17.58 (16.31)	Data  0.74 ( 0.07)	Loss   0.54 (  0.59)	Cls Loss   0.43 (  0.48)	Self Training Loss   0.11 (  0.11)	Cls Acc 78.1 (80.5)	Pseudo Label Acc 82.9 (76.6)	Pseudo Label Ratio 36.5 (40.0)
Epoch: [13][200/500]	Time 16.15 (16.26)	Data  0.02 ( 0.06)	Loss   0.68 (  0.60)	Cls Loss   0.59 (  0.49)	Self Training Loss   0.09 (  0.11)	Cls Acc 75.0 (80.1)	Pseudo Label Acc 75.8 (76.1)	Pseudo Label Ratio 34.4 (39.7)
Epoch: [13][300/500]	Time 16.05 (16.25)	Data  0.01 ( 0.06)	Loss   0.72 (  0.59)	Cls Loss   0.63 (  0.48)	Self Training Loss   0.08 (  0.10)	Cls Acc 71.9 (80.1)	Pseudo Label Acc 81.2 (75.9)	Pseudo Label Ratio 33.3 (39.6)
Epoch: [13][400/500]	Time 17.45 (16.24)	Data  0.72 ( 0.07)	Loss   0.55 (  0.59)	Cls Loss   0.45 (  0.48)	Self Training Loss   0.10 (  0.10)	Cls Acc 81.2 (80.4)	Pseudo Label Acc 74.4 (76.3)	Pseudo Label Ratio 44.8 (39.6)
Test: [ 0/47]	Time  1.341 ( 1.341)	Loss 6.0566e-01 (6.0566e-01)	Acc@1  81.25 ( 81.25)
 * Acc@1 58.59269
 * F1 macro = 0.34096
 * F1 micro= 0.58593
 * precision macro= 0.45723
 * precision micro= 0.58593
 * recall macro = 0.30417
 * recall micro = 0.58593
global correct: 58.6
mean correct:57.6
mean IoU: 38.2
+------------------+-------------------+--------------------+
|      class       |        acc        |        iou         |
+------------------+-------------------+--------------------+
|    E-commerce    | 70.10050201416016 |  66.1137466430664  |
| Video on-demand  | 77.69230651855469 | 26.09819221496582  |
| Interactive data | 25.11848258972168 | 22.457626342773438 |
+------------------+-------------------+--------------------+
lr: [3.674195852021934e-05, 0.00036741958520219336, 0.00036741958520219336]
Epoch: [14][  0/500]	Time 16.70 (16.70)	Data  0.01 ( 0.01)	Loss   0.83 (  0.83)	Cls Loss   0.57 (  0.57)	Self Training Loss   0.26 (  0.26)	Cls Acc 71.9 (71.9)	Pseudo Label Acc 72.1 (72.1)	Pseudo Label Ratio 44.8 (44.8)
Epoch: [14][100/500]	Time 16.18 (16.26)	Data  0.01 ( 0.07)	Loss   0.87 (  0.58)	Cls Loss   0.71 (  0.48)	Self Training Loss   0.16 (  0.10)	Cls Acc 68.8 (79.8)	Pseudo Label Acc 83.3 (77.1)	Pseudo Label Ratio 43.8 (40.0)
Epoch: [14][200/500]	Time 17.43 (16.23)	Data  0.75 ( 0.07)	Loss   0.44 (  0.58)	Cls Loss   0.32 (  0.47)	Self Training Loss   0.12 (  0.10)	Cls Acc 90.6 (80.4)	Pseudo Label Acc 71.4 (76.7)	Pseudo Label Ratio 36.5 (40.1)
Epoch: [14][300/500]	Time 16.10 (16.21)	Data  0.01 ( 0.06)	Loss   0.53 (  0.57)	Cls Loss   0.45 (  0.47)	Self Training Loss   0.08 (  0.10)	Cls Acc 81.2 (80.6)	Pseudo Label Acc 74.3 (76.6)	Pseudo Label Ratio 36.5 (40.5)
Epoch: [14][400/500]	Time 16.16 (16.21)	Data  0.01 ( 0.07)	Loss   0.41 (  0.57)	Cls Loss   0.35 (  0.47)	Self Training Loss   0.07 (  0.10)	Cls Acc 87.5 (80.7)	Pseudo Label Acc 80.0 (76.4)	Pseudo Label Ratio 36.5 (40.5)
Test: [ 0/47]	Time  1.363 ( 1.363)	Loss 5.8589e-01 (5.8589e-01)	Acc@1  81.25 ( 81.25)
 * Acc@1 58.18674
 * F1 macro = 0.34857
 * F1 micro= 0.58187
 * precision macro= 0.47053
 * precision micro= 0.58187
 * recall macro = 0.31433
 * recall micro = 0.58187
global correct: 58.2
mean correct:56.4
mean IoU: 37.4
+------------------+-------------------+--------------------+
|      class       |        acc        |        iou         |
+------------------+-------------------+--------------------+
|    E-commerce    | 71.60803985595703 | 66.74473571777344  |
| Video on-demand  | 75.38461303710938 | 24.873096466064453 |
| Interactive data | 22.27488136291504 | 20.704845428466797 |
+------------------+-------------------+--------------------+
lr: [3.5355339059327384e-05, 0.0003535533905932738, 0.0003535533905932738]
Epoch: [15][  0/500]	Time 17.72 (17.72)	Data  0.69 ( 0.69)	Loss   0.94 (  0.94)	Cls Loss   0.81 (  0.81)	Self Training Loss   0.13 (  0.13)	Cls Acc 62.5 (62.5)	Pseudo Label Acc 69.8 (69.8)	Pseudo Label Ratio 44.8 (44.8)
Epoch: [15][100/500]	Time 16.24 (16.21)	Data  0.01 ( 0.06)	Loss   0.47 (  0.57)	Cls Loss   0.34 (  0.47)	Self Training Loss   0.13 (  0.10)	Cls Acc 90.6 (80.7)	Pseudo Label Acc 80.0 (76.1)	Pseudo Label Ratio 36.5 (39.8)
Epoch: [15][200/500]	Time 16.34 (16.20)	Data  0.02 ( 0.07)	Loss   0.54 (  0.57)	Cls Loss   0.45 (  0.47)	Self Training Loss   0.08 (  0.10)	Cls Acc 81.2 (80.1)	Pseudo Label Acc 75.7 (76.1)	Pseudo Label Ratio 38.5 (39.9)
Epoch: [15][300/500]	Time 17.40 (16.20)	Data  0.73 ( 0.07)	Loss   0.73 (  0.57)	Cls Loss   0.66 (  0.47)	Self Training Loss   0.08 (  0.10)	Cls Acc 75.0 (80.6)	Pseudo Label Acc 72.5 (76.0)	Pseudo Label Ratio 41.7 (40.0)
Epoch: [15][400/500]	Time 16.10 (16.19)	Data  0.01 ( 0.06)	Loss   0.72 (  0.57)	Cls Loss   0.60 (  0.47)	Self Training Loss   0.12 (  0.10)	Cls Acc 68.8 (80.5)	Pseudo Label Acc 68.2 (76.0)	Pseudo Label Ratio 45.8 (40.4)
Test: [ 0/47]	Time  1.254 ( 1.254)	Loss 5.5024e-01 (5.5024e-01)	Acc@1  81.25 ( 81.25)
 * Acc@1 59.47226
 * F1 macro = 0.33542
 * F1 micro= 0.59472
 * precision macro= 0.42763
 * precision micro= 0.59472
 * recall macro = 0.30521
 * recall micro = 0.59472
global correct: 59.5
mean correct:57.9
mean IoU: 38.7
+------------------+--------------------+--------------------+
|      class       |        acc         |        iou         |
+------------------+--------------------+--------------------+
|    E-commerce    | 71.85929107666016  | 65.67163848876953  |
| Video on-demand  | 76.15384674072266  | 26.29482078552246  |
| Interactive data | 25.829383850097656 | 24.061809539794922 |
+------------------+--------------------+--------------------+
lr: [3.408497911293487e-05, 0.00034084979112934867, 0.00034084979112934867]
Epoch: [16][  0/500]	Time 16.60 (16.60)	Data  0.01 ( 0.01)	Loss   0.63 (  0.63)	Cls Loss   0.48 (  0.48)	Self Training Loss   0.15 (  0.15)	Cls Acc 75.0 (75.0)	Pseudo Label Acc 77.8 (77.8)	Pseudo Label Ratio 46.9 (46.9)
Epoch: [16][100/500]	Time 17.38 (16.21)	Data  0.73 ( 0.06)	Loss   0.71 (  0.58)	Cls Loss   0.66 (  0.48)	Self Training Loss   0.05 (  0.10)	Cls Acc 71.9 (81.1)	Pseudo Label Acc 78.0 (75.7)	Pseudo Label Ratio 42.7 (41.3)
Epoch: [16][200/500]	Time 15.99 (16.19)	Data  0.01 ( 0.06)	Loss   0.50 (  0.57)	Cls Loss   0.44 (  0.47)	Self Training Loss   0.06 (  0.10)	Cls Acc 81.2 (80.7)	Pseudo Label Acc 65.8 (75.6)	Pseudo Label Ratio 39.6 (41.0)
Epoch: [16][300/500]	Time 16.10 (16.22)	Data  0.02 ( 0.06)	Loss   0.63 (  0.58)	Cls Loss   0.48 (  0.47)	Self Training Loss   0.15 (  0.10)	Cls Acc 84.4 (80.5)	Pseudo Label Acc 69.8 (76.0)	Pseudo Label Ratio 55.2 (40.8)
Epoch: [16][400/500]	Time 17.42 (16.23)	Data  0.77 ( 0.06)	Loss   0.47 (  0.58)	Cls Loss   0.43 (  0.48)	Self Training Loss   0.04 (  0.10)	Cls Acc 81.2 (80.4)	Pseudo Label Acc 81.1 (76.1)	Pseudo Label Ratio 38.5 (40.8)
Test: [ 0/47]	Time  1.374 ( 1.374)	Loss 7.8255e-01 (7.8255e-01)	Acc@1  81.25 ( 81.25)
 * Acc@1 60.21651
 * F1 macro = 0.35357
 * F1 micro= 0.60217
 * precision macro= 0.45696
 * precision micro= 0.60217
 * recall macro = 0.31689
 * recall micro = 0.60217
global correct: 60.2
mean correct:59.7
mean IoU: 40.0
+------------------+-------------------+--------------------+
|      class       |        acc        |        iou         |
+------------------+-------------------+--------------------+
|    E-commerce    | 70.47738647460938 | 66.46919250488281  |
| Video on-demand  |        80.0       | 27.225130081176758 |
| Interactive data | 28.67298698425293 | 26.419214248657227 |
+------------------+-------------------+--------------------+
lr: [3.291626064807194e-05, 0.0003291626064807194, 0.0003291626064807194]
Epoch: [17][  0/500]	Time 16.80 (16.80)	Data  0.01 ( 0.01)	Loss   0.48 (  0.48)	Cls Loss   0.41 (  0.41)	Self Training Loss   0.06 (  0.06)	Cls Acc 81.2 (81.2)	Pseudo Label Acc 82.9 (82.9)	Pseudo Label Ratio 42.7 (42.7)
Epoch: [17][100/500]	Time 16.21 (16.33)	Data  0.01 ( 0.07)	Loss   0.59 (  0.58)	Cls Loss   0.50 (  0.47)	Self Training Loss   0.09 (  0.10)	Cls Acc 81.2 (80.8)	Pseudo Label Acc 83.3 (76.5)	Pseudo Label Ratio 37.5 (41.7)
Epoch: [17][200/500]	Time 17.63 (16.31)	Data  0.74 ( 0.07)	Loss   0.48 (  0.58)	Cls Loss   0.37 (  0.48)	Self Training Loss   0.11 (  0.10)	Cls Acc 81.2 (80.5)	Pseudo Label Acc 77.5 (76.8)	Pseudo Label Ratio 41.7 (41.5)
Epoch: [17][300/500]	Time 16.25 (16.29)	Data  0.01 ( 0.06)	Loss   0.46 (  0.58)	Cls Loss   0.40 (  0.47)	Self Training Loss   0.06 (  0.10)	Cls Acc 87.5 (80.6)	Pseudo Label Acc 86.0 (76.7)	Pseudo Label Ratio 44.8 (41.6)
Epoch: [17][400/500]	Time 16.36 (16.29)	Data  0.02 ( 0.07)	Loss   0.57 (  0.58)	Cls Loss   0.38 (  0.47)	Self Training Loss   0.18 (  0.10)	Cls Acc 87.5 (80.7)	Pseudo Label Acc 74.4 (76.8)	Pseudo Label Ratio 44.8 (41.9)
Test: [ 0/47]	Time  1.355 ( 1.355)	Loss 7.1729e-01 (7.1729e-01)	Acc@1  81.25 ( 81.25)
 * Acc@1 59.74290
 * F1 macro = 0.34165
 * F1 micro= 0.59743
 * precision macro= 0.43692
 * precision micro= 0.59743
 * recall macro = 0.30659
 * recall micro = 0.59743
global correct: 59.7
mean correct:59.8
mean IoU: 39.6
+------------------+-------------------+--------------------+
|      class       |        acc        |        iou         |
+------------------+-------------------+--------------------+
|    E-commerce    | 69.09547424316406 | 65.08875274658203  |
| Video on-demand  | 81.53845977783203 | 27.785058975219727 |
| Interactive data | 28.67298698425293 | 26.021503448486328 |
+------------------+-------------------+--------------------+
lr: [3.18369625258112e-05, 0.000318369625258112, 0.000318369625258112]
Epoch: [18][  0/500]	Time 17.86 (17.86)	Data  0.72 ( 0.72)	Loss   0.58 (  0.58)	Cls Loss   0.47 (  0.47)	Self Training Loss   0.11 (  0.11)	Cls Acc 78.1 (78.1)	Pseudo Label Acc 66.7 (66.7)	Pseudo Label Ratio 50.0 (50.0)
Epoch: [18][100/500]	Time 16.18 (16.30)	Data  0.01 ( 0.07)	Loss   0.61 (  0.56)	Cls Loss   0.47 (  0.45)	Self Training Loss   0.14 (  0.11)	Cls Acc 81.2 (81.4)	Pseudo Label Acc 78.6 (77.3)	Pseudo Label Ratio 43.8 (42.5)
Epoch: [18][200/500]	Time 15.99 (16.30)	Data  0.01 ( 0.07)	Loss   0.86 (  0.56)	Cls Loss   0.72 (  0.45)	Self Training Loss   0.14 (  0.11)	Cls Acc 65.6 (81.5)	Pseudo Label Acc 71.4 (76.9)	Pseudo Label Ratio 43.8 (42.4)
Epoch: [18][300/500]	Time 17.41 (16.30)	Data  0.74 ( 0.07)	Loss   0.49 (  0.57)	Cls Loss   0.40 (  0.46)	Self Training Loss   0.09 (  0.10)	Cls Acc 84.4 (81.0)	Pseudo Label Acc 76.9 (77.1)	Pseudo Label Ratio 40.6 (42.3)
Epoch: [18][400/500]	Time 16.10 (16.29)	Data  0.01 ( 0.06)	Loss   0.48 (  0.56)	Cls Loss   0.40 (  0.46)	Self Training Loss   0.08 (  0.10)	Cls Acc 87.5 (81.1)	Pseudo Label Acc 77.5 (77.1)	Pseudo Label Ratio 41.7 (41.9)
Test: [ 0/47]	Time  1.312 ( 1.312)	Loss 6.7272e-01 (6.7272e-01)	Acc@1  81.25 ( 81.25)
 * Acc@1 58.52503
 * F1 macro = 0.32477
 * F1 micro= 0.58525
 * precision macro= 0.41665
 * precision micro= 0.58525
 * recall macro = 0.29312
 * recall micro = 0.58525
global correct: 58.5
mean correct:57.9
mean IoU: 37.4
+------------------+--------------------+--------------------+
|      class       |        acc         |        iou         |
+------------------+--------------------+--------------------+
|    E-commerce    | 69.34673309326172  | 59.67567443847656  |
| Video on-demand  | 78.46154022216797  | 29.226360321044922 |
| Interactive data | 25.829383850097656 | 23.290597915649414 |
+------------------+--------------------+--------------------+
lr: [3.0836783520511886e-05, 0.00030836783520511886, 0.00030836783520511886]
Epoch: [19][  0/500]	Time 15.97 (15.97)	Data  0.01 ( 0.01)	Loss   0.47 (  0.47)	Cls Loss   0.39 (  0.39)	Self Training Loss   0.09 (  0.09)	Cls Acc 84.4 (84.4)	Pseudo Label Acc 59.4 (59.4)	Pseudo Label Ratio 33.3 (33.3)
Epoch: [19][100/500]	Time 17.58 (16.27)	Data  0.76 ( 0.07)	Loss   0.82 (  0.55)	Cls Loss   0.72 (  0.45)	Self Training Loss   0.10 (  0.11)	Cls Acc 75.0 (81.6)	Pseudo Label Acc 77.5 (76.3)	Pseudo Label Ratio 41.7 (41.4)
Epoch: [19][200/500]	Time 16.24 (16.27)	Data  0.01 ( 0.06)	Loss   0.59 (  0.56)	Cls Loss   0.49 (  0.45)	Self Training Loss   0.11 (  0.11)	Cls Acc 81.2 (81.7)	Pseudo Label Acc 82.5 (75.8)	Pseudo Label Ratio 41.7 (41.4)
Epoch: [19][300/500]	Time 16.12 (16.27)	Data  0.02 ( 0.06)	Loss   0.92 (  0.56)	Cls Loss   0.80 (  0.46)	Self Training Loss   0.13 (  0.10)	Cls Acc 68.8 (81.2)	Pseudo Label Acc 75.6 (76.5)	Pseudo Label Ratio 42.7 (41.9)
Epoch: [19][400/500]	Time 17.54 (16.27)	Data  0.73 ( 0.07)	Loss   0.66 (  0.57)	Cls Loss   0.55 (  0.46)	Self Training Loss   0.11 (  0.10)	Cls Acc 78.1 (81.3)	Pseudo Label Acc 72.5 (76.7)	Pseudo Label Ratio 41.7 (42.1)
Test: [ 0/47]	Time  1.248 ( 1.248)	Loss 6.3270e-01 (6.3270e-01)	Acc@1  81.25 ( 81.25)
 * Acc@1 59.94587
 * F1 macro = 0.35120
 * F1 micro= 0.59946
 * precision macro= 0.44048
 * precision micro= 0.59946
 * recall macro = 0.32073
 * recall micro = 0.59946
global correct: 59.9
mean correct:58.9
mean IoU: 39.3
+------------------+--------------------+--------------------+
|      class       |        acc         |        iou         |
+------------------+--------------------+--------------------+
|    E-commerce    | 71.48241424560547  | 65.62860870361328  |
| Video on-demand  | 78.07691955566406  | 26.851850509643555 |
| Interactive data | 27.014217376708984 | 25.503355026245117 |
+------------------+--------------------+--------------------+
Elapsed time: 162306.8429043293
best_acc1 = 76.11637
Test: [ 0/47]	Time  1.243 ( 1.243)	Loss 6.5039e-01 (6.5039e-01)	Acc@1  81.25 ( 81.25)
 * Acc@1 76.11637
 * F1 macro = 0.43724
 * F1 micro= 0.76116
 * precision macro= 0.48317
 * precision micro= 0.76116
 * recall macro = 0.41569
 * recall micro = 0.76116
global correct: 76.1
mean correct:77.6
mean IoU: 61.1
+------------------+-------------------+--------------------+
|      class       |        acc        |        iou         |
+------------------+-------------------+--------------------+
|    E-commerce    | 71.60803985595703 |  66.8229751586914  |
| Video on-demand  | 76.92308044433594 | 38.167938232421875 |
| Interactive data | 84.12322235107422 | 78.19383239746094  |
+------------------+-------------------+--------------------+
Test result below...
test_acc1 = 76.11637
F1 macro = 0.43724
F1 micro= 0.76116
precision macro= 0.48317
precision micro= 0.76116
recall macro = 0.41569
recall micro = 0.76116
avg_time = 991.25532
min_time = 176.00000
max_time = 1083.00000
                  precision    recall  f1-score   support

      E-commerce    0.90909   0.71608   0.80112       796
 Video on-demand    0.43103   0.76923   0.55249       260
Interactive data    0.91731   0.84123   0.87763       422

        accuracy                        0.76116      1478
       macro avg    0.75248   0.77551   0.74375      1478
    weighted avg    0.82734   0.76116   0.77923      1478

