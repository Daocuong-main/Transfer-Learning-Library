{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import custom_utils\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.colors as col\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from custom_utils import plot_graph\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchsummary import summary\n",
    "torch.set_printoptions(profile=\"full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import warn\n",
    "from numpy import mean, transpose, cov, cos, sin, shape, exp, newaxis, concatenate\n",
    "from numpy.linalg import linalg, LinAlgError, solve\n",
    "from scipy.stats import chi2\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 2 tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 32])\n",
      "torch.Size([20, 32])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create two random tensors of size (16, 256)\n",
    "A = torch.rand(20, 32)\n",
    "B = torch.rand(20, 32)\n",
    "\n",
    "# Print the resulting tensors\n",
    "print(A.size())\n",
    "print(B.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.1959e-01, 6.7428e-01, 3.7069e-01, 2.3169e-02, 2.8957e-01, 1.1827e-01,\n",
      "         4.7602e-01, 4.1885e-01, 3.9422e-01, 4.9875e-01, 3.4164e-01, 5.7570e-01,\n",
      "         7.4267e-01, 6.7217e-01, 4.5006e-01, 1.7391e-01, 7.1285e-01, 9.9839e-01,\n",
      "         4.3529e-02, 9.4392e-01, 6.8551e-01, 6.8957e-01, 6.1205e-01, 2.2308e-01,\n",
      "         7.4224e-01, 3.0796e-01, 6.6209e-02, 9.4232e-01, 3.1229e-01, 5.3347e-01,\n",
      "         3.6949e-01, 4.3864e-01],\n",
      "        [3.9063e-01, 8.4681e-02, 5.3030e-01, 7.9786e-01, 8.2533e-01, 5.9200e-01,\n",
      "         3.2728e-02, 9.3585e-01, 9.1194e-01, 7.2851e-01, 9.5378e-01, 6.3701e-03,\n",
      "         4.4242e-01, 9.6539e-01, 7.8147e-01, 8.7133e-01, 4.7750e-01, 7.4194e-01,\n",
      "         8.1804e-01, 2.5442e-01, 6.3567e-01, 1.1939e-01, 6.5881e-01, 9.6283e-02,\n",
      "         6.4013e-01, 4.2130e-01, 2.8256e-01, 5.6830e-01, 7.9889e-01, 2.0312e-01,\n",
      "         4.4173e-01, 5.2617e-01],\n",
      "        [6.8637e-01, 8.5880e-01, 3.7349e-01, 7.3831e-02, 9.3800e-02, 2.0373e-01,\n",
      "         7.0021e-01, 9.0923e-01, 5.1898e-02, 8.9422e-01, 7.5866e-01, 6.8126e-01,\n",
      "         4.0579e-01, 2.2456e-01, 8.7694e-01, 5.8620e-01, 2.2376e-01, 3.2974e-01,\n",
      "         6.3435e-01, 3.7876e-01, 6.4214e-01, 2.2429e-01, 8.5618e-01, 7.2748e-02,\n",
      "         9.9108e-01, 9.7554e-01, 4.3129e-01, 6.7017e-01, 8.6935e-01, 8.4855e-01,\n",
      "         9.6222e-01, 4.7976e-01],\n",
      "        [7.9758e-01, 2.3066e-02, 2.9231e-02, 3.0378e-01, 1.9901e-01, 1.4915e-01,\n",
      "         5.7028e-01, 1.3329e-02, 4.1472e-01, 1.1042e-01, 6.1368e-01, 2.3802e-01,\n",
      "         6.2078e-01, 6.5766e-01, 6.5705e-01, 9.0758e-01, 1.2754e-01, 4.7474e-01,\n",
      "         9.3502e-01, 8.1389e-01, 2.0859e-01, 2.4493e-01, 9.4710e-01, 8.1538e-01,\n",
      "         8.4849e-01, 9.3540e-01, 1.3992e-01, 9.0885e-01, 1.0650e-01, 9.5762e-02,\n",
      "         6.3249e-01, 2.6788e-01],\n",
      "        [2.9801e-01, 2.3842e-01, 1.2379e-01, 5.4286e-01, 2.9987e-01, 2.1858e-02,\n",
      "         4.3808e-01, 4.8795e-01, 9.5309e-01, 5.0120e-01, 6.8135e-01, 8.9296e-02,\n",
      "         9.5745e-01, 8.5764e-01, 1.5147e-01, 7.5284e-01, 5.1389e-01, 5.7508e-01,\n",
      "         2.3071e-01, 3.1075e-01, 1.7396e-01, 9.0356e-01, 4.6906e-01, 6.2902e-01,\n",
      "         9.7988e-01, 7.1609e-01, 5.0790e-01, 2.0306e-01, 9.6676e-01, 9.7301e-01,\n",
      "         3.8727e-01, 2.7337e-01],\n",
      "        [3.1145e-01, 9.9536e-01, 7.4117e-01, 8.4460e-01, 2.2686e-02, 5.6877e-01,\n",
      "         1.6966e-01, 3.3466e-01, 7.5669e-01, 2.7085e-01, 7.8872e-01, 5.8482e-01,\n",
      "         6.3558e-02, 1.2002e-01, 1.2763e-01, 2.1493e-01, 2.0764e-01, 7.5925e-01,\n",
      "         5.2703e-01, 3.4554e-02, 7.8802e-01, 5.5805e-01, 4.2165e-01, 4.0751e-01,\n",
      "         1.5957e-01, 7.4653e-01, 2.4338e-01, 5.7021e-01, 7.4097e-01, 6.9396e-01,\n",
      "         1.9871e-01, 1.8300e-01],\n",
      "        [5.2892e-02, 6.2875e-01, 9.6340e-01, 5.8831e-01, 4.0112e-01, 8.1744e-01,\n",
      "         3.4768e-01, 1.3113e-01, 4.6498e-01, 6.2222e-01, 3.1352e-01, 5.1002e-02,\n",
      "         5.8664e-02, 8.0541e-01, 2.9778e-01, 4.6920e-01, 6.2513e-01, 9.6927e-01,\n",
      "         8.5245e-01, 5.8502e-01, 1.1794e-01, 6.9866e-01, 5.0194e-01, 5.9565e-01,\n",
      "         4.2152e-01, 6.2209e-01, 3.0660e-01, 8.7559e-01, 5.2020e-01, 5.9744e-01,\n",
      "         9.2296e-01, 2.4535e-01],\n",
      "        [1.5091e-01, 6.2124e-01, 4.8019e-01, 4.0574e-02, 3.0310e-02, 5.1894e-01,\n",
      "         2.0495e-02, 6.5097e-02, 9.8048e-01, 1.5710e-01, 5.5684e-01, 4.1313e-02,\n",
      "         4.7921e-01, 7.6525e-01, 7.4339e-01, 5.4979e-01, 1.0715e-02, 2.0212e-01,\n",
      "         8.5077e-01, 8.2395e-02, 1.8998e-02, 6.0936e-01, 2.9140e-01, 9.1228e-01,\n",
      "         7.5580e-01, 5.1226e-01, 7.7781e-01, 4.0759e-01, 5.5667e-02, 7.2329e-02,\n",
      "         4.3641e-01, 5.5942e-01],\n",
      "        [9.3547e-01, 1.3537e-01, 3.6721e-02, 3.8539e-01, 4.6967e-01, 6.6524e-01,\n",
      "         1.8446e-01, 6.4982e-01, 7.2721e-01, 3.5289e-01, 9.5111e-01, 7.1117e-01,\n",
      "         1.1054e-01, 9.0496e-01, 7.7456e-01, 5.7813e-01, 7.4096e-01, 1.4140e-01,\n",
      "         9.9730e-01, 5.8499e-01, 7.4601e-01, 6.9537e-01, 6.8677e-01, 3.1027e-01,\n",
      "         2.0437e-01, 4.8686e-01, 8.9142e-01, 8.8502e-01, 1.1668e-01, 6.3131e-01,\n",
      "         1.8195e-01, 2.3828e-01],\n",
      "        [8.8548e-01, 1.9161e-01, 6.8798e-01, 6.5773e-01, 7.4335e-01, 1.3594e-01,\n",
      "         2.3245e-01, 2.2583e-01, 5.3620e-01, 6.6945e-01, 2.8139e-01, 7.8248e-01,\n",
      "         5.1975e-01, 6.5290e-01, 5.8716e-01, 3.5324e-01, 7.9226e-01, 5.2786e-01,\n",
      "         4.8635e-01, 5.5186e-01, 7.5794e-01, 8.7511e-01, 1.3291e-01, 1.4359e-01,\n",
      "         7.4567e-01, 8.1907e-02, 7.9876e-01, 9.2000e-01, 4.7802e-02, 7.7814e-01,\n",
      "         5.1694e-01, 3.9595e-01],\n",
      "        [2.4524e-01, 6.9158e-01, 2.9548e-01, 5.1078e-01, 1.5628e-01, 2.9764e-01,\n",
      "         8.6049e-01, 1.4236e-01, 2.5058e-01, 7.9246e-01, 2.0539e-01, 7.7139e-01,\n",
      "         3.3789e-01, 6.3928e-01, 9.9286e-01, 8.5153e-01, 2.2851e-01, 9.0881e-01,\n",
      "         3.8168e-01, 2.6038e-02, 7.0328e-01, 5.9736e-01, 3.3875e-01, 9.9983e-01,\n",
      "         3.7974e-01, 3.8417e-01, 9.3593e-01, 6.3197e-02, 5.7046e-01, 2.3709e-01,\n",
      "         3.4246e-01, 2.0878e-01],\n",
      "        [7.4663e-01, 5.4573e-02, 8.4914e-01, 7.1114e-01, 1.4799e-01, 8.0712e-01,\n",
      "         6.8592e-01, 5.1670e-01, 4.1732e-01, 7.5781e-02, 6.7957e-01, 1.7152e-01,\n",
      "         6.4131e-01, 8.2621e-01, 2.3573e-01, 1.1461e-01, 6.3111e-01, 8.0767e-01,\n",
      "         3.8170e-01, 7.9905e-01, 1.5320e-01, 8.8216e-01, 3.0003e-01, 8.4729e-01,\n",
      "         9.5729e-01, 6.1372e-01, 7.2230e-03, 1.4408e-01, 5.4474e-01, 4.1852e-01,\n",
      "         7.9775e-01, 8.1269e-01],\n",
      "        [5.9051e-01, 2.6824e-01, 3.7701e-01, 4.3694e-01, 7.7543e-01, 4.1306e-01,\n",
      "         5.9684e-01, 3.2056e-01, 1.0768e-01, 9.3346e-01, 2.2430e-02, 5.0890e-01,\n",
      "         4.9062e-01, 5.6554e-01, 2.2985e-02, 5.9310e-01, 4.8112e-01, 1.9204e-01,\n",
      "         4.3356e-01, 2.8864e-01, 2.0183e-01, 9.0707e-01, 1.7994e-01, 9.1683e-01,\n",
      "         6.1536e-01, 7.2207e-01, 4.2396e-02, 2.9894e-03, 3.9364e-01, 3.9663e-01,\n",
      "         2.1499e-01, 3.5486e-01],\n",
      "        [4.9772e-01, 2.8399e-01, 3.0001e-01, 2.8728e-01, 6.4072e-01, 7.8117e-01,\n",
      "         7.7760e-04, 6.9774e-01, 7.9765e-02, 2.8731e-01, 3.0541e-01, 9.0304e-01,\n",
      "         3.6165e-01, 7.1622e-02, 8.4564e-01, 9.7401e-01, 2.8205e-02, 1.0760e-01,\n",
      "         9.0418e-01, 2.1990e-01, 1.7574e-02, 9.1243e-01, 5.5198e-01, 1.5861e-01,\n",
      "         5.7138e-01, 9.9484e-01, 2.9522e-01, 8.2252e-01, 4.5235e-01, 7.7694e-01,\n",
      "         6.4001e-01, 8.2191e-01],\n",
      "        [3.9820e-01, 7.0519e-01, 9.4394e-02, 1.3645e-01, 1.2518e-01, 6.8227e-01,\n",
      "         5.3168e-01, 4.9799e-01, 5.8459e-02, 3.9404e-01, 1.2402e-01, 5.9738e-01,\n",
      "         1.5806e-01, 2.4074e-01, 9.9306e-02, 7.4377e-01, 1.1192e-01, 9.2423e-01,\n",
      "         1.3064e-01, 3.8550e-01, 3.4194e-01, 8.9628e-01, 2.4563e-01, 7.4874e-01,\n",
      "         2.7090e-01, 4.1961e-01, 4.1756e-01, 7.3865e-01, 1.1207e-01, 6.1732e-01,\n",
      "         8.6987e-02, 8.0212e-01],\n",
      "        [9.4463e-02, 2.9371e-01, 6.3312e-01, 2.0077e-01, 8.1613e-01, 9.3412e-01,\n",
      "         9.6115e-01, 3.5830e-02, 1.8776e-01, 2.7721e-01, 2.4111e-01, 1.7033e-02,\n",
      "         8.4699e-01, 6.4816e-01, 4.3862e-01, 2.8369e-01, 3.7430e-02, 1.3708e-01,\n",
      "         3.1982e-01, 7.3023e-01, 8.5679e-01, 5.1683e-01, 5.1188e-01, 9.9210e-01,\n",
      "         3.6167e-01, 9.5293e-01, 1.0217e-01, 3.7309e-01, 6.9772e-02, 5.8910e-01,\n",
      "         2.7465e-01, 3.9601e-01],\n",
      "        [8.0561e-01, 3.0739e-01, 3.8511e-01, 3.5775e-01, 2.3814e-01, 1.7884e-01,\n",
      "         1.9311e-01, 4.1885e-01, 8.7833e-02, 5.4357e-02, 2.5968e-01, 4.7555e-01,\n",
      "         9.1526e-01, 7.6546e-01, 5.3907e-01, 8.6256e-01, 8.5573e-01, 8.8004e-01,\n",
      "         2.8131e-01, 5.3178e-01, 4.2907e-01, 9.2238e-01, 9.7785e-01, 1.8022e-01,\n",
      "         8.7711e-01, 9.6151e-02, 3.4678e-01, 8.4889e-01, 4.1459e-01, 6.4696e-01,\n",
      "         1.0248e-01, 6.8990e-01],\n",
      "        [9.2848e-02, 2.4071e-01, 6.3638e-01, 1.9232e-01, 4.9792e-01, 7.6710e-01,\n",
      "         1.9436e-01, 3.0676e-01, 9.9271e-01, 4.3135e-02, 5.9806e-01, 1.0743e-01,\n",
      "         2.1789e-01, 3.0990e-01, 8.7079e-01, 4.3826e-01, 9.8327e-01, 3.2871e-02,\n",
      "         6.5853e-01, 7.1073e-01, 2.8924e-01, 3.3920e-01, 9.1889e-01, 9.5571e-01,\n",
      "         1.3792e-01, 9.9900e-01, 2.7822e-01, 1.5594e-01, 1.7351e-01, 4.6121e-01,\n",
      "         4.9498e-01, 1.8360e-01],\n",
      "        [9.8413e-01, 5.7462e-01, 7.9576e-01, 4.2708e-02, 8.6937e-01, 8.0824e-01,\n",
      "         1.1867e-02, 5.3811e-01, 9.3066e-01, 3.6399e-01, 9.4409e-01, 5.6431e-01,\n",
      "         6.2441e-01, 4.4552e-01, 6.2140e-01, 2.5641e-01, 6.5996e-01, 5.8945e-01,\n",
      "         7.5128e-01, 3.9335e-01, 2.2464e-02, 8.7548e-02, 1.0388e-01, 4.0358e-01,\n",
      "         9.3498e-01, 1.1576e-03, 7.9074e-01, 9.3690e-01, 4.8746e-01, 9.7356e-01,\n",
      "         5.6223e-01, 3.9739e-01],\n",
      "        [1.6742e-01, 4.0312e-01, 4.9186e-01, 8.9543e-01, 8.9134e-02, 7.9356e-01,\n",
      "         6.2970e-01, 6.7322e-01, 4.0610e-02, 1.4329e-01, 4.1963e-01, 7.5706e-01,\n",
      "         6.6250e-02, 1.0127e-01, 4.4154e-01, 8.4696e-01, 6.4500e-01, 8.5725e-01,\n",
      "         3.1924e-01, 5.9831e-01, 7.6814e-01, 7.5023e-01, 8.8645e-01, 7.1986e-01,\n",
      "         6.6144e-01, 7.5324e-01, 7.9641e-01, 8.3713e-01, 3.3202e-01, 1.4830e-01,\n",
      "         1.6921e-01, 3.6792e-01]])\n"
     ]
    }
   ],
   "source": [
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image, target_size=(32, 32)):\n",
    "    return cv2.resize(image, target_size, interpolation=cv2.INTER_LINEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1013,
   "metadata": {},
   "outputs": [],
   "source": [
    "# points = numpy.random.randn(2, 256)\n",
    "# points = torch.randn(2, 256)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1014,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mahalanobis_distance(difference, num_random_features):\n",
    "    num_samples, _ = shape(difference)\n",
    "    sigma = cov(transpose(difference))\n",
    "\n",
    "    try:\n",
    "        linalg.inv(sigma)\n",
    "    except LinAlgError:\n",
    "        warn('covariance matrix is singular. Pvalue returned is 1.1')\n",
    "        raise\n",
    "\n",
    "    mu = mean(difference, 0)\n",
    "\n",
    "    if num_random_features == 1:\n",
    "        stat = float(num_samples * mu ** 2) / float(sigma)\n",
    "    else:\n",
    "        print('Original')\n",
    "        solve_function = solve(sigma, transpose(mu))\n",
    "        print(f'solve_function:\\n{solve_function}')\n",
    "        right_side = mu.dot(solve_function)\n",
    "        print(f'right_side:\\n{right_side} **')\n",
    "        stat = num_samples * right_side\n",
    "\n",
    "    return chi2.sf(stat, num_random_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1015,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanEmbeddingTest:\n",
    "\n",
    "    def __init__(self, data_x, data_y, scale=1, number_of_random_frequencies=5):\n",
    "        self.data_x = scale*data_x\n",
    "        self.data_y = scale*data_y\n",
    "        self.number_of_frequencies = number_of_random_frequencies\n",
    "        self.scale = scale\n",
    "\n",
    "    def get_estimate(self, data, point):\n",
    "        z = data - self.scale * point\n",
    "        z2 = numpy.linalg.norm(z, axis=1)**2\n",
    "        return numpy.exp(-z2/2.0)\n",
    "\n",
    "\n",
    "    def get_difference(self, point):\n",
    "        return self.get_estimate(self.data_x, point) - self.get_estimate(self.data_y, point)\n",
    "\n",
    "\n",
    "    def vector_of_differences(self, dim):\n",
    "        points = numpy.random.randn(self.number_of_frequencies, dim)\n",
    "        a = [self.get_difference(point) for point in points]\n",
    "        return numpy.array(a).T\n",
    "\n",
    "    def compute_pvalue(self):\n",
    "\n",
    "        _, dimension = numpy.shape(self.data_x)\n",
    "        obs = self.vector_of_differences(dimension)\n",
    "\n",
    "        return mahalanobis_distance(obs, self.number_of_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original\n",
      "solve_function:\n",
      "[-1.64265500e+98 -1.18128473e+98]\n",
      "right_side:\n",
      "0.16125854497196118 **\n",
      "transfer_loss: 0.27525196628393006\n"
     ]
    }
   ],
   "source": [
    "mkme_loss = MeanEmbeddingTest(A, B, scale=1, number_of_random_frequencies=2)\n",
    "transfer_loss = mkme_loss.compute_pvalue()\n",
    "print(f'transfer_loss: {transfer_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1017,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(data):\n",
    "    w = linalg.norm(data, axis=1)\n",
    "    print('after norm')\n",
    "    print(w)\n",
    "    beta = -w ** 2 / 2.0\n",
    "    print('beta')\n",
    "    print(beta)\n",
    "    w = exp(beta)\n",
    "    print('after exp')\n",
    "    print(w)\n",
    "    return w[:, newaxis]\n",
    "\n",
    "\n",
    "def smooth_cf(data, w, random_frequencies):\n",
    "    n, _ = data.shape\n",
    "    _, d = random_frequencies.shape\n",
    "    mat = data.dot(random_frequencies)\n",
    "    arr = concatenate((sin(mat) * w, cos(mat) * w), 1)\n",
    "    n1, d1 = arr.shape\n",
    "    assert n1 == n and d1 == 2 * d and w.shape == (n, 1)\n",
    "    return arr\n",
    "\n",
    "\n",
    "def smooth_difference(random_frequencies, X, Y):\n",
    "    x_smooth = smooth(X)\n",
    "    y_smooth = smooth(Y)\n",
    "    characteristic_function_x = smooth_cf(X, x_smooth, random_frequencies)\n",
    "    characteristic_function_y = smooth_cf(Y, y_smooth, random_frequencies)\n",
    "    return characteristic_function_x - characteristic_function_y\n",
    "\n",
    "class SmoothCFTest:\n",
    "\n",
    "    def _gen_random(self, dimension):\n",
    "        return numpy.random.randn(dimension, self.num_random_features)\n",
    "\n",
    "\n",
    "    def __init__(self, data_x, data_y, scale, num_random_features, frequency_generator=None):\n",
    "        self.data_x = scale*data_x.detach().cpu().numpy()\n",
    "        self.data_y = scale*data_y.detach().cpu().numpy()\n",
    "        self.num_random_features = num_random_features\n",
    "\n",
    "        _, dimension_x = numpy.shape(self.data_x)\n",
    "        _, dimension_y = numpy.shape(self.data_y)\n",
    "        assert dimension_x == dimension_y\n",
    "        self.random_frequencies = self._gen_random(dimension_x)\n",
    "\n",
    "\n",
    "    def compute_pvalue(self):\n",
    "\n",
    "        difference = smooth_difference(self.random_frequencies, self.data_x, self.data_y)\n",
    "        return mahalanobis_distance(difference, 2 * self.num_random_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1018,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after norm\n",
      "[17.299675  15.755465  15.693022  15.9108715 16.26306   17.860605\n",
      " 14.877518  15.766319  16.149252  16.292368  16.076368  15.546218\n",
      " 15.941503  16.281757  16.616148  16.971794 ]\n",
      "beta\n",
      "[-149.63937  -124.11733  -123.13547  -126.57792  -132.24356  -159.50061\n",
      " -110.670265 -124.288414 -130.39917  -132.72063  -129.22481  -120.842445\n",
      " -127.06575  -132.5478   -138.04819  -144.0209  ]\n",
      "after exp\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "after norm\n",
      "[16.238874 16.428133 16.914322 15.943955 15.773848 16.411478 16.847824\n",
      " 15.950004 15.305755 15.590869 14.610736 15.231061 15.188093 14.33715\n",
      " 15.91739  15.268224]\n",
      "beta\n",
      "[-131.85052  -134.94177  -143.04715  -127.10486  -124.407135 -134.6683\n",
      " -141.92459  -127.20131  -117.133064 -121.5376   -106.7368   -115.99261\n",
      " -115.33909  -102.77693  -126.68165  -116.559326]\n",
      "after exp\n",
      "[0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00\n",
      " 0.e+00 0.e+00 0.e+00 3.e-45 0.e+00 0.e+00]\n",
      "Original\n",
      "solve_function:\n",
      "[-2.36974918e+44 -1.78405962e+44 -7.13623846e+44  1.78405962e+44]\n",
      "right_side:\n",
      "0.0625 **\n",
      "transfer_loss: 0.9097959895689501\n"
     ]
    }
   ],
   "source": [
    "mkme_loss = SmoothCFTest(A, B, scale=1, num_random_features=2)\n",
    "transfer_loss = mkme_loss.compute_pvalue()\n",
    "print(f'transfer_loss: {transfer_loss}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### custom_eu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1019,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mahalanobis_distance(difference, num_random_features):\n",
    "    num_samples, _ = difference.shape\n",
    "    sigma = torch.cov(difference.T)\n",
    "    mu = torch.mean(difference, 0)\n",
    "    if num_random_features == 1:\n",
    "        stat = float(num_samples * torch.pow(mu, 2)) / float(sigma)\n",
    "    else:\n",
    "        right_side = torch.matmul(mu, mu.T)\n",
    "        print(f'right_side:\\n{right_side}')\n",
    "        stat = num_samples * right_side\n",
    "        print(f'stat:\\n{stat}')\n",
    "    return chi2.sf(stat.detach().cpu(), num_random_features)\n",
    "\n",
    "\n",
    "class MeanEmbeddingTest:\n",
    "\n",
    "    def __init__(self, data_x, data_y, scale, number_of_random_frequencies, device):\n",
    "        self.device = device\n",
    "        self.data_x = scale * data_x.to(device)\n",
    "        self.data_y = scale * data_y.to(device)\n",
    "        self.number_of_frequencies = number_of_random_frequencies\n",
    "        self.scale = scale\n",
    "\n",
    "    def get_estimate(self, data, point):\n",
    "        z = data - self.scale * point\n",
    "        z2 = torch.norm(z, p=2, dim=1)**2\n",
    "        return torch.exp(-z2/2.0)\n",
    "\n",
    "    def get_difference(self, point):\n",
    "        return self.get_estimate(self.data_x, point) - self.get_estimate(self.data_y, point)\n",
    "\n",
    "    def vector_of_differences(self, dim):\n",
    "        points = torch.tensor(numpy.random.randn(\n",
    "            self.number_of_frequencies, dim)).to(self.device)\n",
    "        a = [self.get_difference(point) for point in points]\n",
    "        return torch.stack(a).T\n",
    "\n",
    "    def compute_pvalue(self):\n",
    "\n",
    "        _, dimension = self.data_x.size()\n",
    "        obs = self.vector_of_differences(dimension)\n",
    "        return mahalanobis_distance(obs, self.number_of_frequencies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1020,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right_side:\n",
      "1.842170648771096e-179\n",
      "stat:\n",
      "2.947473038033754e-178\n",
      "transfer_loss: 1.0\n"
     ]
    }
   ],
   "source": [
    "mkme_loss = MeanEmbeddingTest(A, B ,scale=1, number_of_random_frequencies=2, device=device)\n",
    "transfer_loss = mkme_loss.compute_pvalue()\n",
    "print(f'transfer_loss: {transfer_loss}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1021,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(data):\n",
    "    print('data')\n",
    "    print(data)\n",
    "    w = torch.linalg.norm(data, dim=1)\n",
    "    print('after norm')\n",
    "    print(w)\n",
    "    print(f'-torch.pow(w,2): {-torch.pow(w,2)}')\n",
    "    w = torch.exp(-w ** 2 / 2.0)\n",
    "    print('after exp')\n",
    "    print(w)\n",
    "    return w[:, newaxis]\n",
    "\n",
    "\n",
    "def smooth_cf(data, w, random_frequencies):\n",
    "    n, _ = data.shape\n",
    "    _, d = random_frequencies.shape\n",
    "    mat = torch.matmul(data,random_frequencies)\n",
    "    arr = torch.cat((torch.sin(mat) * w, torch.cos(mat) * w), dim = 1)\n",
    "    n1, d1 = arr.shape\n",
    "    assert n1 == n and d1 == 2 * d and w.shape == (n, 1)\n",
    "    return arr\n",
    "\n",
    "\n",
    "def smooth_difference(random_frequencies, X, Y):\n",
    "    x_smooth = smooth(X)\n",
    "    y_smooth = smooth(Y)\n",
    "    characteristic_function_x = smooth_cf(X, x_smooth, random_frequencies)\n",
    "    characteristic_function_y = smooth_cf(Y, y_smooth, random_frequencies)\n",
    "    return characteristic_function_x - characteristic_function_y\n",
    "\n",
    "class SmoothCFTest:\n",
    "\n",
    "    def _gen_random(self, dimension):\n",
    "        return torch.tensor(numpy.random.randn(dimension, self.num_random_features).astype(np.float32)).to(self.device)\n",
    "\n",
    "\n",
    "    def __init__(self, data_x, data_y, scale, num_random_features, device, frequency_generator=None):\n",
    "        self.device = device\n",
    "        self.data_x = scale*data_x.to(self.device)\n",
    "        self.data_y = scale*data_y.to(self.device)\n",
    "        self.num_random_features = num_random_features\n",
    "\n",
    "        _, dimension_x = numpy.shape(self.data_x)\n",
    "        _, dimension_y = numpy.shape(self.data_y)\n",
    "        assert dimension_x == dimension_y\n",
    "        self.random_frequencies = self._gen_random(dimension_x)\n",
    "\n",
    "\n",
    "    def compute_pvalue(self):\n",
    "        difference = smooth_difference(self.random_frequencies, self.data_x, self.data_y)\n",
    "        return mahalanobis_distance(difference, 2 * self.num_random_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1022,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n",
      "tensor([[ 0.8408,  0.6097,  2.6534,  ...,  0.6043, -1.8668, -0.1236],\n",
      "        [-2.3901, -0.0141, -0.2644,  ..., -0.7488,  1.0507, -0.8017],\n",
      "        [-0.7533, -0.9772, -0.6795,  ...,  0.6511, -1.3017, -2.2515],\n",
      "        ...,\n",
      "        [ 2.0089,  0.5029, -1.0588,  ..., -0.7731,  0.9187, -0.5550],\n",
      "        [-0.4826, -0.2987,  0.1411,  ...,  0.7256,  1.5195,  2.2034],\n",
      "        [ 0.9428, -1.2763, -0.9038,  ...,  1.2772, -2.3631,  0.6699]],\n",
      "       device='cuda:0')\n",
      "after norm\n",
      "tensor([17.2997, 15.7555, 15.6930, 15.9109, 16.2631, 17.8606, 14.8775, 15.7663,\n",
      "        16.1493, 16.2924, 16.0764, 15.5462, 15.9415, 16.2818, 16.6161, 16.9718],\n",
      "       device='cuda:0')\n",
      "-torch.pow(w,2): tensor([-299.2788, -248.2347, -246.2709, -253.1558, -264.4871, -319.0012,\n",
      "        -221.3405, -248.5769, -260.7983, -265.4413, -258.4496, -241.6849,\n",
      "        -254.1315, -265.0956, -276.0964, -288.0418], device='cuda:0')\n",
      "after exp\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0')\n",
      "data\n",
      "tensor([[ 1.5641,  0.4190, -2.4232,  ..., -1.3903,  0.0599, -0.9379],\n",
      "        [-0.9723,  0.5265, -1.1163,  ..., -0.4942,  0.5062,  0.1536],\n",
      "        [ 0.0041,  1.4940,  0.6590,  ...,  0.5077, -0.4379, -0.4075],\n",
      "        ...,\n",
      "        [-0.6148, -1.1801,  0.4408,  ...,  0.6528, -1.2169, -0.4973],\n",
      "        [-0.7193,  0.6277,  2.5577,  ...,  0.2492,  0.2679, -0.8633],\n",
      "        [-0.0909,  2.8726,  0.0671,  ...,  0.3895,  0.4903, -0.9225]],\n",
      "       device='cuda:0')\n",
      "after norm\n",
      "tensor([16.2389, 16.4281, 16.9143, 15.9440, 15.7738, 16.4115, 16.8478, 15.9500,\n",
      "        15.3058, 15.5909, 14.6107, 15.2311, 15.1881, 14.3371, 15.9174, 15.2682],\n",
      "       device='cuda:0')\n",
      "-torch.pow(w,2): tensor([-263.7011, -269.8836, -286.0943, -254.2097, -248.8143, -269.3366,\n",
      "        -283.8492, -254.4026, -234.2661, -243.0752, -213.4736, -231.9852,\n",
      "        -230.6782, -205.5539, -253.3633, -233.1187], device='cuda:0')\n",
      "after exp\n",
      "tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 2.8026e-45, 0.0000e+00, 0.0000e+00], device='cuda:0')\n",
      "right_side:\n",
      "0.0\n",
      "stat:\n",
      "0.0\n",
      "transfer_loss: 1.0\n"
     ]
    }
   ],
   "source": [
    "mkme_loss = SmoothCFTest(\n",
    "    A, B, scale=1, num_random_features=2, device=device)\n",
    "transfer_loss = mkme_loss.compute_pvalue()\n",
    "print(f'transfer_loss: {transfer_loss}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pinverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1023,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mahalanobis_distance(difference, num_random_features):\n",
    "    num_samples, _ = difference.shape\n",
    "    sigma = torch.cov(difference.T)\n",
    "    mu = torch.mean(difference, 0)\n",
    "    if num_random_features == 1:\n",
    "        stat = float(num_samples * torch.pow(mu,2)) / float(sigma)\n",
    "    else:\n",
    "        sigma = torch.pinverse(sigma)\n",
    "        mathmul_function = torch.matmul(sigma, mu.T)\n",
    "        print(f'mathmul_function:\\n{mathmul_function}')\n",
    "        right_side =  torch.matmul(mu, mathmul_function)\n",
    "        print(f'right_side:\\n{right_side}')\n",
    "        stat = num_samples * right_side\n",
    "    return chi2.sf(stat.detach().cpu(), num_random_features)\n",
    "\n",
    "class MeanEmbeddingTest:\n",
    "\n",
    "    def __init__(self, data_x, data_y, scale, number_of_random_frequencies, device):\n",
    "        self.device = device\n",
    "        self.data_x = scale * data_x.to(device)\n",
    "        self.data_y = scale * data_y.to(device)\n",
    "        self.number_of_frequencies = number_of_random_frequencies\n",
    "        self.scale = scale\n",
    "\n",
    "    def get_estimate(self, data, point):\n",
    "        z = data - self.scale * point\n",
    "        z2 = torch.norm(z, p=2, dim=1)**2\n",
    "        return torch.exp(-z2/2.0)\n",
    "\n",
    "    def get_difference(self, point):\n",
    "        return self.get_estimate(self.data_x, point) - self.get_estimate(self.data_y, point)\n",
    "\n",
    "    def vector_of_differences(self, dim):\n",
    "        points = torch.tensor(numpy.random.randn(self.number_of_frequencies, dim)).to(device)\n",
    "        a = [self.get_difference(point) for point in points]\n",
    "        return torch.stack(a).T\n",
    "\n",
    "    def compute_pvalue(self):\n",
    "\n",
    "        _, dimension = self.data_x.size()\n",
    "        obs = self.vector_of_differences(dimension)\n",
    "        return mahalanobis_distance(obs, self.number_of_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1024,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mathmul_function:\n",
      "tensor([-3.2029e+95, -4.4704e+97], device='cuda:0', dtype=torch.float64)\n",
      "right_side:\n",
      "0.13254002980381024\n",
      "transfer_loss: 0.3463448796282109\n"
     ]
    }
   ],
   "source": [
    "mkme_loss = MeanEmbeddingTest(\n",
    "    A, B, scale=1, number_of_random_frequencies=2, device=device)\n",
    "transfer_loss = mkme_loss.compute_pvalue()\n",
    "print(f'transfer_loss: {transfer_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1025,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(data):\n",
    "    print('data')\n",
    "    print(data)\n",
    "    w = torch.linalg.norm(data, dim=1)\n",
    "    print('after norm')\n",
    "    print(w)\n",
    "    print(f'-torch.pow(w,2): {-torch.pow(w,2)}')\n",
    "    w = torch.exp(-w ** 2 / 2.0)\n",
    "    print('after exp')\n",
    "    print(w)\n",
    "    return w[:, newaxis]\n",
    "\n",
    "\n",
    "def smooth_cf(data, w, random_frequencies):\n",
    "    n, _ = data.shape\n",
    "    _, d = random_frequencies.shape\n",
    "    mat = torch.matmul(data,random_frequencies)\n",
    "    arr = torch.cat((torch.sin(mat) * w, torch.cos(mat) * w), dim = 1)\n",
    "    n1, d1 = arr.shape\n",
    "    assert n1 == n and d1 == 2 * d and w.shape == (n, 1)\n",
    "    return arr\n",
    "\n",
    "\n",
    "def smooth_difference(random_frequencies, X, Y):\n",
    "    x_smooth = smooth(X)\n",
    "    y_smooth = smooth(Y)\n",
    "    characteristic_function_x = smooth_cf(X, x_smooth, random_frequencies)\n",
    "    characteristic_function_y = smooth_cf(Y, y_smooth, random_frequencies)\n",
    "    return characteristic_function_x - characteristic_function_y\n",
    "\n",
    "class SmoothCFTest:\n",
    "\n",
    "    def _gen_random(self, dimension):\n",
    "        return torch.tensor(numpy.random.randn(dimension, self.num_random_features).astype(np.float32)).to(self.device)\n",
    "\n",
    "\n",
    "    def __init__(self, data_x, data_y, scale, num_random_features, device, frequency_generator=None):\n",
    "        self.device = device\n",
    "        self.data_x = scale*data_x.to(self.device)\n",
    "        self.data_y = scale*data_y.to(self.device)\n",
    "        self.num_random_features = num_random_features\n",
    "\n",
    "        _, dimension_x = numpy.shape(self.data_x)\n",
    "        _, dimension_y = numpy.shape(self.data_y)\n",
    "        assert dimension_x == dimension_y\n",
    "        self.random_frequencies = self._gen_random(dimension_x)\n",
    "\n",
    "\n",
    "    def compute_pvalue(self):\n",
    "        difference = smooth_difference(self.random_frequencies, self.data_x, self.data_y)\n",
    "        return mahalanobis_distance(difference, 2 * self.num_random_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1026,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n",
      "tensor([[ 0.8408,  0.6097,  2.6534,  ...,  0.6043, -1.8668, -0.1236],\n",
      "        [-2.3901, -0.0141, -0.2644,  ..., -0.7488,  1.0507, -0.8017],\n",
      "        [-0.7533, -0.9772, -0.6795,  ...,  0.6511, -1.3017, -2.2515],\n",
      "        ...,\n",
      "        [ 2.0089,  0.5029, -1.0588,  ..., -0.7731,  0.9187, -0.5550],\n",
      "        [-0.4826, -0.2987,  0.1411,  ...,  0.7256,  1.5195,  2.2034],\n",
      "        [ 0.9428, -1.2763, -0.9038,  ...,  1.2772, -2.3631,  0.6699]],\n",
      "       device='cuda:0')\n",
      "after norm\n",
      "tensor([17.2997, 15.7555, 15.6930, 15.9109, 16.2631, 17.8606, 14.8775, 15.7663,\n",
      "        16.1493, 16.2924, 16.0764, 15.5462, 15.9415, 16.2818, 16.6161, 16.9718],\n",
      "       device='cuda:0')\n",
      "-torch.pow(w,2): tensor([-299.2788, -248.2347, -246.2709, -253.1558, -264.4871, -319.0012,\n",
      "        -221.3405, -248.5769, -260.7983, -265.4413, -258.4496, -241.6849,\n",
      "        -254.1315, -265.0956, -276.0964, -288.0418], device='cuda:0')\n",
      "after exp\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0')\n",
      "data\n",
      "tensor([[ 1.5641,  0.4190, -2.4232,  ..., -1.3903,  0.0599, -0.9379],\n",
      "        [-0.9723,  0.5265, -1.1163,  ..., -0.4942,  0.5062,  0.1536],\n",
      "        [ 0.0041,  1.4940,  0.6590,  ...,  0.5077, -0.4379, -0.4075],\n",
      "        ...,\n",
      "        [-0.6148, -1.1801,  0.4408,  ...,  0.6528, -1.2169, -0.4973],\n",
      "        [-0.7193,  0.6277,  2.5577,  ...,  0.2492,  0.2679, -0.8633],\n",
      "        [-0.0909,  2.8726,  0.0671,  ...,  0.3895,  0.4903, -0.9225]],\n",
      "       device='cuda:0')\n",
      "after norm\n",
      "tensor([16.2389, 16.4281, 16.9143, 15.9440, 15.7738, 16.4115, 16.8478, 15.9500,\n",
      "        15.3058, 15.5909, 14.6107, 15.2311, 15.1881, 14.3371, 15.9174, 15.2682],\n",
      "       device='cuda:0')\n",
      "-torch.pow(w,2): tensor([-263.7011, -269.8836, -286.0943, -254.2097, -248.8143, -269.3366,\n",
      "        -283.8492, -254.4026, -234.2661, -243.0752, -213.4736, -231.9852,\n",
      "        -230.6782, -205.5539, -253.3633, -233.1187], device='cuda:0')\n",
      "after exp\n",
      "tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 2.8026e-45, 0.0000e+00, 0.0000e+00], device='cuda:0')\n",
      "mathmul_function:\n",
      "tensor([0., 0., 0., 0.], device='cuda:0')\n",
      "right_side:\n",
      "0.0\n",
      "transfer_loss: 1.0\n"
     ]
    }
   ],
   "source": [
    "mkme_loss = SmoothCFTest(\n",
    "    A, B, scale=1, num_random_features=2, device=device)\n",
    "transfer_loss = mkme_loss.compute_pvalue()\n",
    "print(f'transfer_loss: {transfer_loss}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
